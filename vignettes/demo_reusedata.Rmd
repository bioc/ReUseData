```{R}
devtools::load_all()
library(Rcwl)
```

# For developers: update/search/make recipe, generate data.  

## recipeUpdate take private GitHub repo

```{r recipeUpdate_private_repo}
recipeUpdate(cachePath = "ReUseDataRecipe-private", repo="Liubuntu/ReUseDataRecipe_private")  ## works!
recipeSearch("gencode", cachePath="ReUseDataRecipe-private")  ## works!
```

## Example 1: reference genome GRCh38, Homo sapiens, MT
```{r recipeMake_ref21} 
script <- "
chr=$1
wget http://ftp.ensembl.org/pub/release-104/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.$chr.fa.gz
gzip -d Homo_sapiens.GRCh38.dna.chromosome.$chr.fa.gz 
samtools faidx Homo_sapiens.GRCh38.dna.chromosome.$chr.fa
bwa index Homo_sapiens.GRCh38.dna.chromosome.$chr.fa
"
ref <- recipeMake(shscript = script,
                  paramID = c("chr"),
                  paramType = c("string"), ## FIXME: require a data.frame, ID, type, check columns for NA, etc. In R, no long in R, use double? Validate! 2e54.(integer, 53 bits integer precision)
                  outputID = "ref_genome",  ## outputType: File[] in code. 
                  outputGlob = "Homo_sapiens.*",   
                  requireTools = c("samtools=1.3", "bwa")  ## name must exactly match the tool name.
                  )
ref$chr <- "MT" ## FIXME: validate AEAP!! 
res <- getData(ref,  ## FIXME: check existence (warning, overwrite=TRUE) automatic directory gen related to that recipe!!!
               outdir = "../SharedData/tmp",
               prefix = "ref_genome_MT",
               notes = c("reference", "genome", "MT", "human"),
               version = "v0",
               ## docker = TRUE, ## by default: TRUE. 
               cwlArgs = "--tmpdir-prefix tmp/")  ## a fix for my desktop, https://cwl.discourse.group/t/docker-error-invalid-mount-config-for-type-bind/598
```

## Example 2: gencode gtf file download and unzip

```{r recipeMake_gencode}  
file.copy("/home/qian/workspace/SharedData/gencode_human_38.sh", "gencode_test.sh")
dd <- recipeMake(shscript = "gencode_test.sh", 
                 paramID = c("species", "version"),
                 paramType = c("string", "string"),
                 outputID = "gencode_gtf",  ## outputType: by default, File[]
                 outputGlob = "*.gtf"
                 ## , requireTools = c() ## wget, gzip 
                 )  
inputs(dd)
dd$species <- "human"
dd$version <- "38"
getData(dd,
        outdir = "../SharedData",
        prefix = "gencode_human_38",
        notes = c("gencode", "human", "38"),
        version = "v0",
        ## docker = TRUE,  ## corresponds to recipeMake(requireTools)
        cwlArgs = "--tmpdir-prefix tmp/"
        )

dd$species <- "mouse"
dd$version <- "M27"
getData(dd,
        outdir = "../SharedData",
        prefix = "gencode_mouse_M27",
        notes = c("gencode", "mouse", "M27"),
        version = "v0",
        ## docker = TRUE,
        cwlArgs = "--tmpdir-prefix tmp/"
        )
```

## Example 4: 
```{r}
script <- "
species=$1
version=$2
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_$species/release_$version/gencode.v$version.transcripts.fa.gz
"
gencode_transcriptome <- recipeMake(script, 
                                    paramID = c("species", "version"),
                                    paramType = c("character", "character"),
                                    outputGlob = "*.transcripts.fa.gz")
## write above into .R script, upload to ReUseDataRecipe github repo
gencode_ref$species <- "mouse"
gencode_ref$version <- "M31" 
getData(gencode, outdir = "../SharedData",
        prefix = "gencode_mouse_M31",
        notes = c("gencode", "mouse", "M31"),
        version = "v0")

```
## Example 3: genome lift-over download 

```{r recipeMake_liftover}
script <- "
from=$1
to=$2
wget https://ftp.ensembl.org/pub/assembly_mapping/homo_sapiens/${from}_to_${to}.chain.gz"
rcp_liftover <- recipeMake(shscript = script,
                           paramID = c("from", "to"),  ## required for "recipeMake"?? ## FIXME: add default value or pass check. 
                           paramType = c("string", "string"),  ## FIXME: remove requirement in "recipeMake". 
                           outputID = "genome_lift_over",  ## same as above?? 
                           outputGlob = "*.chain.gz")  ## required for "getData" creating md4sum file?

## put above code into "genome_liftover.R" and upload to "https://github.com/rworkflow/ReUseDataRecipe". 
rm(rcp_liftover)

## update, search, and load new recipe
recipeUpdate()
recipeSearch("liftover")
rcp_liftover <- recipeLoad("genome_liftover")

## evaluate recipe to generate data 
inputs(rcp_liftover)
rcp_liftover$from <- "GRCh37"
rcp_liftover$to <- "GRCh38"
getData(rcp_liftover,
        outdir = "../SharedData",
        prefix = "liftover",
        notes = c("lift_over", "GRCh37 to GRCh38"),  ## "notes" will be pasted with " ", so avoid using blank space for notes.
        version = "v0",
        ## cwlArgs = "--tmpdir-prefix tmp/",
        showLog=TRUE)

## add meta data for recipe
devtools::load_all("../RcwlMeta")
rcp_liftover <- addMeta(cwl = rcp_liftover,
                        label = "liftover",
                        doc = "genome liftover",
                        inputLabels = c("from", "to"),
                        inputDocs = c("original genome build", "target genome build"))
cat(meta2md(rcp_liftover))
## FIXME: in "meta2md", need to read mtime which is not currently available in data recipes: mcols(recipeSearch("liftover"))$mtime
```

# For users

step 1: [dataUpdate()], dataSearch(), return ("dataHub"? with) data path. 
step 2: if data not exist, [recipeUpdate()], recipeSearch(), return ("dataHub"? with) filepath in local cache. 

## Using data

update all data records, and search data. 

```{r, eval = FALSE}
datapath <- "~/workspace/SharedData"  ## save data to a shared folder in group
dataUpdate(dir = datapath, outMeta = TRUE) ## search local cache (a shared folder within the group) for all available YAML file (go with each data), return a table for all available data.  
aa <- dataSearch(c("gencode", "human", "38")) ## return a "dataHub" object, showing data path. 
``` 

Internally, `meta_data` was run inside `data_Update`, to generate a
summary table for all available dataset by reading the .yml files.

```{r}
metaData <- meta_data(dir = datapath)
```

## Data not exist

Update data recipes from GitHub (`recipeUpdate`), search data recipes
(`recipeSearch`), generate data (`getData`), and write to shared
folder (needs writing permission).

```{r} 
recipeUpdate()
recipeSearch("gencode")  ## return a "dataHub" with recipe name. (recipes are "rcwlProcess" object)
rcp <- recipeLoad("gencode_gtf")  ## load recipe from local rworkflows/ReUseDataRecipes repo.

rcp
inputs(rcp)

rcp$specie = "human"
rcp$version = "38"

res <- getData(rcp, outdir = datapath,
               prefix = "gencode_human_38", 
               note = c("human", "gencode", "gtf"), ## recommended!
               showLog=TRUE,
               docker = FALSE)
dataSearch(c("gencode", "human", "38"))

gencode_gtf$specie <- "mouse"
gencode_gtf$version <- "M27"
res1 <- getData(gencode_gtf, outdir = datapath,
                prefix = "gencode_mouse_M27",
                note = c("mouse", "gencode", "gtf"),
                showLog = TRUE,
                docker = FALSE)
dataSearch(c("gencode", "mouse", "M27"))

recipeSearch(c("STAR", "index"))
rcp <- recipeLoad("STAR_index")

inputs(rcp)
rcp$ref <- ""
rcp$gtf <- ""
rcp$genomeDir <- "STARindex"
rcp$threads <- 1
rcp$sjdb <- 100

getData(rcp, outdir = datapath,
           prefix = "reference_genome_",
           note = c("reference", "genome", "human"),
           showLog = TRUE)
```

## Recipe not exist

- make a request to administrator. OR 
- write your own script to get data (downloading/curation, etc.),
  referring to the available scripts:
  https://github.com/rworkflow/ReUseDataRecipe


## todo:

1. getData, always print "Note" and "Version"? -- DONE!
2. create a "meta_recipe.csv", searchable by recipeSearch() function.  -- REMOVE!
3. create a "meta_data.csv", searchable by dataSearch() function.  -- DONE! 
   - `meta_data(dir)` can be multiple paths... 
4. "recipeUpdate()": cache existing recipes from GitHub.   -- DONE!
5. "recipeSearch()" to search cached path of recipe. -- DONE!
6. "recipeLoad()", run the recipe as a whole, and generate a cwlProcess object, only load the cwlProcess object into R, assign values, and generate data. -- renamed as "getData"???
7. "dataUpdate" function: cache existing data by providing the datapath, generate a bfc in cachepath (e.g., "ReUseData") for search purpose.   -- DONE! 
8. "dataSearch()" use keywords to search existing data in bfc. -- DONE!
   - exact match? currently case sensitive by `bfcquery()`... 
   
9. create "dataHub" class, extend "cwlHub", only show some info, e.g., rid, fpath, Version, Date, etc.  -- DONE!
10. FIXME update "recipeLoad(cachePath=)", with support of github repo "rworkflows/ReUseDataRecipes". 

## Questions:


## Data aggregate by software
```{r}
dataUpdate("/projects/rpci/shared/references/")
recipeSearch("reference", "ReUseDataRecipe-private")
dat1 <- dataSearch(c("reference","fasta", "hs37d5"))
dat2 <- dataSearch(c("GENCODE"))


## setMethod("[", c("dataHub"), function(x, i) {
##     rids <- x@rid[i]
##     return(x[rids])
## })
## setGeneric("[")

## setMethod("c", c("dataHub"), function(x, ...) {
##     object <- list(x, ...)
##     rids <- unlist(lapply(object, function(x)x@rid))
##     x@rid <- unique(rids)
##     return(x)
## })

## setGeneric("c")

## setMethod("as.list", c("dataHub"), function(x, type = NULL) {
##     tl <- title(x)
##     pth <- dataPath(x)
##     if(!is.null(type) && type == "cwl"){
##         dtype <- unlist(lapply(pth, function(x)file.info(x)$isdir))
##         dtype <- ifelse(dtype, "Directory", "File")
##         dl <- vector("list", length(pth))
##         for(i in 1:length(pth)){
##             dl[[i]] <- list(class = dtype[i],
##                             path = pth[i])
##         }
##     }else{
##         dl <- as.list(dataPath(x))
##     }
##     names(dl) <- title(x)
##     return(dl)
## })
## setGeneric("as.list")

## tag <- function(object){
##     mcols(object)$tag
## }
## "tag<-" <- function(object, value, append = TRUE){
##     ## mcols(dat1)@listData$tag <- value
##     if(append){
##         value <- paste0(tag(object), value)
##     }
##     dm <- bfcmeta(object, "dataMeta")
##     idx <- match(object@rid, dm$rid)
##     dm$tag[idx] <- value
##     bfc <- BiocFileCache(object@cache, ask = FALSE)
##     bfcmeta(bfc, "dataMeta", overwrite = TRUE) <- dm
##     return(object)
## }


## tags <- function(object){
##     mcols(object)[, c("fpath", "tag")]
## }
## #' @param values A data.frame of fpath and tags to update the metadata.
## "tags<-" <- function(object, values){
##     dm <- bfcmeta(object, "dataMeta")
##     rids <- object@rid[match(values$fpath, dataPath(object))]
##     dm$tag[match(rids, dm$rid)] <- values$tag

##     bfc <- BiocFileCache(object@cache, ask = FALSE)
##     bfcmeta(bfc, "dataMeta", overwrite = TRUE) <- dm
##     return(object)
## }

### Example
dat1 <- dataSearch(c("reference","STAR", "GRCh38"))
dat2 <- dataSearch(c("GENCODE"))

## merge for STAR alignment
r1 <- c(dat1[17], dat2[2])

tag(r1, append=F) <- rep("#STAR#GRCh38", 2)
tag(r1)

## use example
r2 <- dataSearch("#STAR")
to_list(r2)
to_list(r2, "cwl")

tags(r2)

## mutect2
script <- "
path=$1
idx=$2
wget https://storage.googleapis.com/$path
if [ ! -z $idx ]; then wget https://storage.googleapis.com/$path.$idx; fi
"
googleBucket <- recipeMake(shscript = script,
                           paramID = c("rpath", "index"),
                           paramType = c("string", "string?"),
                           outputID = "dfile",
                           outputGlob = "$(inputs.rpath.split('/').slice(-1)[0])*")

googleBucket$rpath <- "gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf"
googleBucket$index <- "idx"
getData(googleBucket,
        outdir = "../SharedData/Mutect2",
        prefix = "Mutect2-exome-panel",
        notes = c("mutect2", "b37", "exome-panel", "pon"), showLog=TRUE)

## googleBucket$rpath <- "gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf"
## googleBucket$index <- "idx"
## getData(googleBucket,
##         outdir = "../SharedData/Mutect2",
##         prefix = "af-only-gnomad",
##         notes = c("mutect2", "b37", "af-only-gnomad"), showLog=TRUE)

googleBucket$rpath <- "gatk-best-practices/somatic-b37/small_exac_common_3.vcf"
googleBucket$index <- "idx"
getData(googleBucket,
        outdir = "../SharedData/Mutect2",
        prefix = "small_exac_common_3",
        notes = c("mutect2", "b37", "small_exac_common"), showLog=TRUE)

dataUpdate("../SharedData")

r3 <- dataSearch("mutect2")
r3 <- r3[c(1,3)]
tag(r3) <- rep("#mutect2#b37", 2)

r3 <- dataSearch(c("#mutect2", "#b37"))
toList(r3)
toList(r3, "cwl")
```
