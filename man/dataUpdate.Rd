% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataUpdate.R
\name{dataUpdate}
\alias{dataUpdate}
\title{dataUpdate}
\usage{
dataUpdate(
  dir,
  cachePath = "ReUseData",
  outMeta = FALSE,
  keepTags = TRUE,
  cleanup = TRUE,
  cloud = FALSE
)
}
\arguments{
\item{dir}{a character string for the directory where all data are
saved. Data information will be collected recursively within
this directory.}

\item{cachePath}{A character string specifying the name for the
\code{BiocFileCache} object to store all the curated data
resources. Once specified, must match the \code{cachePath} argument
in \code{dataSearch}. Default is "ReUseData".}

\item{outMeta}{Logical. If TRUE, a "meta_data.csv" file will be
generated in the \code{dir}, containing information about all
available datasets in the directory: The file path to the yaml
files, and yaml entries including parameter values for data
recipe, file path to datasets, notes, version (from
\code{getData()}), tag (from \code{dataTag()}) if available and data
generating date.}

\item{keepTags}{If keep the prior assigned data tags. Default is
TRUE.}

\item{cleanup}{If remove any invalid intermediate files. Default is
FALSE. In cases one data recipe (with same parameter values)
was evaluated multiple times, the same data file(s) will match
to multiple intermeidate files (e.g., .yml). \code{cleanup} will
remove older intermediate files, and only keep the most recent
ones that matches the data file. When there are any
intermediate files that don't match to any data file, \code{cleanup}
will also remove those.}

\item{cloud}{Whether to return the pre-generated data from Google
Cloud bucket of ReUseData. Default is FALSE.}
}
\value{
a \code{dataHub} object containing the information about local
data cache, e.g., data name, data path, etc.
}
\description{
Function to update the local data records by reading the yaml files
in the specified directory recursively.
}
\details{
Users can directly retrieve information for all available
datasets by using \code{meta_data(dir=)}, which generates a data
frame in R with same information as described above and can be
saved out. \code{dataUpdate} does extra check for all datasets
(check the file path in "output" column), remove invalid ones,
e.g., empty or non-existing file path, and create a data cache
for all valid datasets.
}
\examples{
## Generate data 
recipeLoad("gencode_transcripts", return=TRUE)
inputs(gencode_transcripts)
gencode_transcripts$species <- "human"
gencode_transcripts$version <- "42"
outdir <- file.path(tempdir(), "SharedData")
res <- getData(gencode_transcripts,
        outdir = outdir, 
        notes = c("gencode", "human", "42"),
        showLog = TRUE)

## Update data cache (with or without pre-built data sets from ReUseData cloud bucket
dataUpdate(dir = outdir)
dataUpdate(dir = outdir, cloud = TRUE)

## newly generated data are now cached and searchable
dataSearch(c("gencode", "42"))

}
