[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/articles/ReUseData_data.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"ReUseData: Reusable and Reproducible Data Management","text":"Install package Bioconductor. Use development version: Load package packages used vignette R session.","code":"if (!requireNamespace(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\") BiocManager::install(\"ReUseData\") BiocManager::install(\"ReUseData\", version = \"devel\") suppressPackageStartupMessages(library(Rcwl)) library(ReUseData)"},{"path":"/articles/ReUseData_data.html","id":"reusedata-core-functions-for-data-management","dir":"Articles","previous_headings":"","what":"ReUseData core functions for data management","title":"ReUseData: Reusable and Reproducible Data Management","text":"introduce core functions ReUseData data management reuse: getData reproducible data generation, dataUpdate syncing updating data cache, dataSearch multi-keywords searching dataset interest.","code":""},{"path":"/articles/ReUseData_data.html","id":"data-generation","dir":"Articles","previous_headings":"ReUseData core functions for data management","what":"Data generation","title":"ReUseData: Reusable and Reproducible Data Management","text":"First, can construct data recipes transforming shell ad hoc data preprocessing scripts workflow-based data recipes. prebuilt data recipes public data resources (e.g., downloading, unzipping indexing) available direct use recipeSearch recipeLoad functions. assign values input parameters evaluate recipe generate data interest. Users can assign values input parameters, evaluate recipe (getData) generate data interest. Users need specify output directory files (desired data file, intermediate files internally generated workflow scripts annotation files). Detailed notes data encouraged used keywords matching later data search. can install cwltool first make sure cwl-runner available. file path newly generated dataset can easily retrieved. can also retrieved using dataSearch() functions multiple keywords. , dataUpdate() needs done. automatically generated files help track data recipe evaluation, including *.sh record original shell script, *.cwl file official workflow script internally submitted data recipe evaluation, *.yml file part CWL workflow evaluation, also record data annotations, *.md5 checksum file check/verify integrity generated data file. *.yml file contains information recipe input parameters, file path output file, notes dataset, auto-added date data generation time. later data search using dataSearch() refer file keywords match.","code":"## set cache in tempdir for test Sys.setenv(cachePath = file.path(tempdir(), \"cache\"))  recipeUpdate() #> Updating recipes... #> bowtie2_index.R added #> echo_out.R added #> ensembl_liftover.R added #> gcp_broad_gatk_hg19.R added #> gcp_broad_gatk_hg38.R added #> gcp_gatk_mutect2_b37.R added #> gcp_gatk_mutect2_hg38.R added #> gencode_annotation.R added #> gencode_genome_grch38.R added #> gencode_transcripts.R added #> hisat2_index.R added #> reference_genome.R added #> salmon_index.R added #> STAR_index.R added #> ucsc_database.R added #>  #> recipeHub with 15 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>           name                #>   BFC1  | bowtie2_index       #>   BFC2  | echo_out            #>   BFC3  | ensembl_liftover    #>   BFC4  | gcp_broad_gatk_hg19 #>   BFC5  | gcp_broad_gatk_hg38 #>   ...     ...                 #>   BFC11 | hisat2_index        #>   BFC12 | reference_genome    #>   BFC13 | salmon_index        #>   BFC14 | STAR_index          #>   BFC15 | ucsc_database recipeSearch(\"echo\") #> recipeHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>          name     #>   BFC2 | echo_out echo_out <- recipeLoad(\"echo_out\") #> Note: you need to assign a name for the recipe: rcpName <- recipeLoad('xx') #> Data recipe loaded! #> Use inputs() to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/echo_out.html #> for user instructions (e.g., eligible input values, data source, etc.) inputs(echo_out) #> inputs: #>   input (input)  (string):   #>   outfile (outfile)  (string): invisible(Rcwl::install_cwltool()) echo_out$input <- \"Hello World!\" echo_out$outfile <- \"outfile\" outdir <- file.path(tempdir(), \"SharedData\") res <- getData(echo_out,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\")) #> }INFO Final process status is success res$output #> [1] \"/tmp/RtmpXMx6sd/SharedData/outfile.txt\" list.files(outdir, pattern = \"echo\") #> [1] \"echo_out_Hello_World!_outfile.cwl\" \"echo_out_Hello_World!_outfile.md5\" #> [3] \"echo_out_Hello_World!_outfile.sh\"  \"echo_out_Hello_World!_outfile.yml\" readLines(res$yml) #> [1] \"input: Hello World!\"                              #> [2] \"outfile: outfile\"                                 #> [3] \"# output: /tmp/RtmpXMx6sd/SharedData/outfile.txt\" #> [4] \"# notes: echo hello world txt\"                    #> [5] \"# date: 2023-11-22 22:21:02.021824\""},{"path":"/articles/ReUseData_data.html","id":"data-caching-updating-and-searching","dir":"Articles","previous_headings":"ReUseData core functions for data management","what":"Data caching, updating and searching","title":"ReUseData: Reusable and Reproducible Data Management","text":"dataUpdate() creates (first time use), syncs updates local cache curated datasets. finds reads .yml files recursively provided data folder, creates cache record dataset associated (including newly generated ones getData()), updates local cache later data searching reuse. IMPORTANT: recommended users create specified folder data archival (e.g., file/path//SharedData) group members access , use sub-folders different kinds datasets (e.g., generated recipe). dataUpdate dataSearch return dataHub object list available matching datasets. One can subset list [ use getter functions retrieve annotation information data, e.g., data names, parameters values recipe, notes, tags, corresponding yaml file. ReUseData, name suggests, commits promoting data reuse. Data can prepared standard input formats (toList), e.g., YAML JSON, easily integrated workflow methods locally cloud-hosted. Data can also aggregated different resources tagging specific software tools.","code":"(dh <- dataUpdate(dir = outdir)) #>  #> Updating data record... #> outfile.txt added #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt dh[1] #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt ## dh[\"BFC1\"] dh[dataNames(dh) == \"outfile.txt\"] #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt dataNames(dh) #> [1] \"outfile.txt\" dataParams(dh) #> [1] \"input: Hello World!; outfile: outfile\" dataNotes(dh) #> [1] \"echo hello world txt\" dataTags(dh) #> [1] \"\" dataYml(dh) #> [1] \"/tmp/RtmpXMx6sd/SharedData/echo_out_Hello_World!_outfile.yml\" (dh1 <- dataSearch(c(\"echo\", \"hello\", \"world\"))) #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt toList(dh1, listNames = c(\"input_file\")) #> $input_file #> [1] \"/tmp/RtmpXMx6sd/SharedData/outfile.txt\" toList(dh1, format = \"yaml\", listNames = c(\"input_file\")) #> [1] \"input_file: /tmp/RtmpXMx6sd/SharedData/outfile.txt\" toList(dh1, format = \"json\", file = file.path(tempdir(), \"data.json\")) #> File is saved as: \"/tmp/RtmpXMx6sd/data.json\" #> { #>   \"outfile.txt\": \"/tmp/RtmpXMx6sd/SharedData/outfile.txt\" #> } dataSearch() #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt dataTags(dh[1]) <- \"#gatk\" dataSearch(\"#gatk\") #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt"},{"path":"/articles/ReUseData_data.html","id":"existing-data-annotation","dir":"Articles","previous_headings":"ReUseData core functions for data management","what":"Existing data annotation","title":"ReUseData: Reusable and Reproducible Data Management","text":"package can also used add annotation notes existing data resources experiment data management. add exisiting “exp_data” local data repository. first add notes data, update data repository information new dataset. Now data hub cached meta information two different directories, one data recipe one exisiting data. Data can retrieved keywords. NOTE: argument cloud=TRUE enabled, dataUpdate() also cache pregenerated data sets (evaluation public ReUseData recipes) available ReUseData google bucket return dataHub object fully searchable. Please see following section details.","code":"exp_data <- file.path(tempdir(), \"exp_data\") dir.create(exp_data) annData(exp_data, notes = c(\"experiment data\")) #> meta.yml added #> [1] \"/tmp/RtmpXMx6sd/exp_data/meta.yml\" dataUpdate(exp_data) #>  #> Updating data record... #> exp_data added #> dataHub with 2 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name        Path                                   #>   BFC1 | outfile.txt /tmp/RtmpXMx6sd/SharedData/outfile.txt #>   BFC2 | exp_data    /tmp/RtmpXMx6sd/exp_data dataSearch(\"experiment\") #> dataHub with 1 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>          name     Path                     #>   BFC2 | exp_data /tmp/RtmpXMx6sd/exp_data"},{"path":"/articles/ReUseData_data.html","id":"cloud-data-resources","dir":"Articles","previous_headings":"","what":"Cloud data resources","title":"ReUseData: Reusable and Reproducible Data Management","text":"prebuilt data recipes curation (e.g., downloading, unzipping, indexing) commonly used public data resources pregenerated data sets put cloud space direct use. searching, one need use dataUpdate(cloud=TRUE) sync existing data sets cloud, dataSearch() can used search available data set either local cache cloud. data interest already exist cloud, getCloudData directly download data computer. Add local caching system using dataUpdate() later use. Now create data cache local data files, can see downloaded data available. data supports user-friendly discovery access ReUseData portal, detailed instructions provided straight-forward incorporation data analysis pipelines run local computing nodes, web resources, cloud computing platforms (e.g., Terra, CGC).","code":"gcpdir <- file.path(tempdir(), \"gcpData\") dataUpdate(gcpdir, cloud=TRUE) #>  #> Updating data record... #> 35ddd53464774_GRCh38.primary_assembly.genome.fa.1.bt2 added #> 35ddd24d1ee6f_GRCh38.primary_assembly.genome.fa.2.bt2 added #> 35ddd55648fe3_GRCh38.primary_assembly.genome.fa.3.bt2 added #> 35ddd2a852212_GRCh38.primary_assembly.genome.fa.4.bt2 added #> 35ddd499a6fda_GRCh38.primary_assembly.genome.fa.rev.1.bt2 added #> 35ddd5cbe42ee_GRCh38.primary_assembly.genome.fa.rev.2.bt2 added #> 35ddd2598047d_outfile.txt added #> 35ddd2d330d9_GRCh37_to_GRCh38.chain added #> 35ddd5a31bf7_GRCh37_to_NCBI34.chain added #> 35ddd49f79d5d_GRCh37_to_NCBI35.chain added #> 35dddf75980e_GRCh37_to_NCBI36.chain added #> 35ddd2d15ce58_GRCh38_to_GRCh37.chain added #> 35ddd6eca4166_GRCh38_to_NCBI34.chain added #> 35ddd4f0e372a_GRCh38_to_NCBI35.chain added #> 35ddd27a79a04_GRCh38_to_NCBI36.chain added #> 35ddd7696527d_NCBI34_to_GRCh37.chain added #> 35dddf8757b0_NCBI34_to_GRCh38.chain added #> 35ddd658bb06e_NCBI35_to_GRCh37.chain added #> 35ddd663bca71_NCBI35_to_GRCh38.chain added #> 35ddd3abdd4f_NCBI36_to_GRCh37.chain added #> 35ddd3eb5025b_NCBI36_to_GRCh38.chain added #> 35ddd12c34cb1_GRCm38_to_NCBIM36.chain added #> 35ddd521d52d4_GRCm38_to_NCBIM37.chain added #> 35ddd457bb785_NCBIM36_to_GRCm38.chain added #> 35ddd68fff932_NCBIM37_to_GRCm38.chain added #> 35dddf63b2e6_1000G_omni2.5.b37.vcf.gz added #> 35ddd6055da0c_1000G_omni2.5.b37.vcf.gz.tbi added #> 35ddd1ab67c12_Mills_and_1000G_gold_standard.indels.b37.vcf.gz added #> 35ddd32f81c4b_Mills_and_1000G_gold_standard.indels.b37.vcf.gz.tbi added #> 35ddd163ef277_1000G_omni2.5.hg38.vcf.gz added #> 35ddd25d4cc50_1000G_omni2.5.hg38.vcf.gz.tbi added #> 35ddd63e63bf_Mills_and_1000G_gold_standard.indels.hg38.vcf.gz added #> 35ddd3b10e0e6_Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi added #> 35ddd7b395c33_af-only-gnomad.raw.sites.vcf added #> 35ddd30c385d1_af-only-gnomad.raw.sites.vcf.idx added #> 35ddd4ab50c1_Mutect2-exome-panel.vcf.idx added #> 35ddd57f79f21_Mutect2-WGS-panel-b37.vcf added #> 35ddd565b8a4e_Mutect2-WGS-panel-b37.vcf.idx added #> 35ddd77e819a_small_exac_common_3.vcf added #> 35ddd5d9abb19_small_exac_common_3.vcf.idx added #> 35ddd205327ab_1000g_pon.hg38.vcf.gz added #> 35ddd16f419a8_1000g_pon.hg38.vcf.gz.tbi added #> 35dddab08971_af-only-gnomad.hg38.vcf.gz added #> 35dddf1d6911_af-only-gnomad.hg38.vcf.gz.tbi added #> 35ddd660250d2_small_exac_common_3.hg38.vcf.gz added #> 35ddd32582375_small_exac_common_3.hg38.vcf.gz.tbi added #> 35ddd5b3bb8e_gencode.v41.annotation.gtf added #> 35ddd7589a882_gencode.v42.annotation.gtf added #> 35ddd17e3d3e4_gencode.vM30.annotation.gtf added #> 35ddd6bef8600_gencode.vM31.annotation.gtf added #> 35ddd793585d1_gencode.v41.transcripts.fa added #> 35ddd5698d63f_gencode.v41.transcripts.fa.fai added #> 35ddd7eb2d2b1_gencode.v42.transcripts.fa added #> 35ddd4b52d8a5_gencode.v42.transcripts.fa.fai added #> 35ddd1c148dc4_gencode.vM30.pc_transcripts.fa added #> 35ddd67b2cbe3_gencode.vM30.pc_transcripts.fa.fai added #> 35ddd5ab68b8c_gencode.vM31.pc_transcripts.fa added #> 35ddd7c6a67d0_gencode.vM31.pc_transcripts.fa.fai added #> 35ddd26947f6_GRCh38.primary_assembly.genome.fa.1.ht2 added #> 35ddddaea7d7_GRCh38.primary_assembly.genome.fa.2.ht2 added #> 35ddd12a95a48_GRCh38.primary_assembly.genome.fa.3.ht2 added #> 35ddd283e1446_GRCh38.primary_assembly.genome.fa.4.ht2 added #> 35ddd13ed0b96_GRCh38.primary_assembly.genome.fa.5.ht2 added #> 35ddd4dba3b2e_GRCh38.primary_assembly.genome.fa.6.ht2 added #> 35ddd23777079_GRCh38.primary_assembly.genome.fa.7.ht2 added #> 35ddd44b09167_GRCh38.primary_assembly.genome.fa.8.ht2 added #> 35ddd52658bef_GRCh38_full_analysis_set_plus_decoy_hla.fa.fai added #> 35ddd7b6f0f9b_GRCh38_full_analysis_set_plus_decoy_hla.fa.amb added #> 35ddd1b0c1bb5_GRCh38_full_analysis_set_plus_decoy_hla.fa.ann added #> 35ddd59e40d89_GRCh38_full_analysis_set_plus_decoy_hla.fa.bwt added #> 35ddd5909cab4_GRCh38_full_analysis_set_plus_decoy_hla.fa.pac added #> 35ddd3b5f4361_GRCh38_full_analysis_set_plus_decoy_hla.fa.sa added #> 35ddd70d82731_GRCh38_full_analysis_set_plus_decoy_hla.fa added #> 35ddd63ba5425_GRCh38.primary_assembly.genome.fa.fai added #> 35ddd4a7cac72_GRCh38.primary_assembly.genome.fa.amb added #> 35ddd56da7803_GRCh38.primary_assembly.genome.fa.ann added #> 35ddd1612779b_GRCh38.primary_assembly.genome.fa.bwt added #> 35ddd50306801_GRCh38.primary_assembly.genome.fa.pac added #> 35ddd4c642085_GRCh38.primary_assembly.genome.fa.sa added #> 35ddd2df64b7f_GRCh38.primary_assembly.genome.fa added #> 35ddd3c1fee01_hs37d5.fa.fai added #> 35ddd4599a657_hs37d5.fa.amb added #> 35ddd48f21be_hs37d5.fa.ann added #> 35ddd3ad2c0b2_hs37d5.fa.bwt added #> 35ddd10ec7efc_hs37d5.fa.pac added #> 35ddd20a3af83_hs37d5.fa.sa added #> 35ddd22858c96_hs37d5.fa added #> 35ddd6ba30a88_complete_ref_lens.bin added #> 35ddd1d0e1753_ctable.bin added #> 35ddd24eed48c_ctg_offsets.bin added #> 35ddd7951b25f_duplicate_clusters.tsv added #> 35ddd2fb7719b_info.json added #> 35ddd4d2ce8d2_mphf.bin added #> 35dddd3ebdf5_pos.bin added #> 35ddd7d71acca_pre_indexing.log added #> 35ddd70a4594b_rank.bin added #> 35ddd51ef4f5c_ref_indexing.log added #> 35ddd4fd738b9_refAccumLengths.bin added #> 35ddd6c1368e6_reflengths.bin added #> 35ddd6cfb6b12_refseq.bin added #> 35ddd29bb4643_seq.bin added #> 35ddd451d339a_versionInfo.json added #> 35ddd285aae73_salmon_index added #> 35ddd1a936d74_chrLength.txt added #> 35ddd28d787c0_chrName.txt added #> 35ddd72d75ae5_chrNameLength.txt added #> 35ddd716de578_chrStart.txt added #> 35ddd3ee9ff5b_exonGeTrInfo.tab added #> 35ddd4307c2e6_exonInfo.tab added #> 35ddd3dd205fd_geneInfo.tab added #> 35ddd6ce04ada_Genome added #> 35ddd7f27b0e7_genomeParameters.txt added #> 35ddd36bac54_Log.out added #> 35ddd716f6c98_SA added #> 35ddd39fa719a_SAindex added #> 35ddd14582b51_sjdbInfo.txt added #> 35ddd12131c1b_sjdbList.fromGTF.out.tab added #> 35ddd5c7ffe30_sjdbList.out.tab added #> 35ddd7ffb35d9_transcriptInfo.tab added #> 35ddd2f21336f_GRCh38.GENCODE.v42_100 added #> 35ddd16ed2bc_knownGene_hg38.sql added #> 35ddd794ce839_knownGene_hg38.txt added #> 35ddd5ed8a50a_refGene_hg38.sql added #> 35ddd4e9bbb8e_refGene_hg38.txt added #> 35ddd68ba62e_knownGene_mm39.sql added #> 35ddd5c4a51d4_knownGene_mm39.txt added #> 35ddd3f4014d9_refGene_mm39.sql added #> 35ddd587af58b_refGene_mm39.txt added #> dataHub with 130 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>            name                                    #>   BFC1   | outfile.txt                             #>   BFC2   | exp_data                                #>   BFC3   | GRCh38.primary_assembly.genome.fa.1.bt2 #>   BFC4   | GRCh38.primary_assembly.genome.fa.2.bt2 #>   BFC5   | GRCh38.primary_assembly.genome.fa.3.bt2 #>   ...      ...                                     #>   BFC126 | refGene_hg38.txt                        #>   BFC127 | knownGene_mm39.sql                      #>   BFC128 | knownGene_mm39.txt                      #>   BFC129 | refGene_mm39.sql                        #>   BFC130 | refGene_mm39.txt                        #>          Path                                                                #>   BFC1   /tmp/RtmpXMx6sd/SharedData/outfile.txt                              #>   BFC2   /tmp/RtmpXMx6sd/exp_data                                            #>   BFC3   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC4   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC5   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   ...    ...                                                                 #>   BFC126 https://storage.googleapis.com/reusedata/ucsc_database/refGene_h... #>   BFC127 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC128 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC129 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC130 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... (dh <- dataSearch(c(\"ensembl\", \"GRCh38\"))) #> dataHub with 8 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>           name                   #>   BFC10 | GRCh37_to_GRCh38.chain #>   BFC14 | GRCh38_to_GRCh37.chain #>   BFC15 | GRCh38_to_NCBI34.chain #>   BFC16 | GRCh38_to_NCBI35.chain #>   BFC17 | GRCh38_to_NCBI36.chain #>   BFC19 | NCBI34_to_GRCh38.chain #>   BFC21 | NCBI35_to_GRCh38.chain #>   BFC23 | NCBI36_to_GRCh38.chain #>         Path                                                                #>   BFC10 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh37... #>   BFC14 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh38... #>   BFC15 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh38... #>   BFC16 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh38... #>   BFC17 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh38... #>   BFC19 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI34... #>   BFC21 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI35... #>   BFC23 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI36... getCloudData(dh[1], outdir = gcpdir) #> Data is downloaded:  #> /tmp/RtmpXMx6sd/gcpData/GRCh37_to_GRCh38.chain dataUpdate(gcpdir)  ## Update local data cache (without cloud data) #>  #> Updating data record... #> GRCh37_to_GRCh38.chain added #> dataHub with 131 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>            name                                    #>   BFC1   | outfile.txt                             #>   BFC2   | exp_data                                #>   BFC3   | GRCh38.primary_assembly.genome.fa.1.bt2 #>   BFC4   | GRCh38.primary_assembly.genome.fa.2.bt2 #>   BFC5   | GRCh38.primary_assembly.genome.fa.3.bt2 #>   ...      ...                                     #>   BFC127 | knownGene_mm39.sql                      #>   BFC128 | knownGene_mm39.txt                      #>   BFC129 | refGene_mm39.sql                        #>   BFC130 | refGene_mm39.txt                        #>   BFC131 | GRCh37_to_GRCh38.chain                  #>          Path                                                                #>   BFC1   /tmp/RtmpXMx6sd/SharedData/outfile.txt                              #>   BFC2   /tmp/RtmpXMx6sd/exp_data                                            #>   BFC3   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC4   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC5   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   ...    ...                                                                 #>   BFC127 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC128 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC129 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC130 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC131 /tmp/RtmpXMx6sd/gcpData/GRCh37_to_GRCh38.chain dataSearch()  ## data is available locally!!! #> dataHub with 131 records #> cache path:  /tmp/RtmpXMx6sd/cache/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>            name                                    #>   BFC1   | outfile.txt                             #>   BFC2   | exp_data                                #>   BFC3   | GRCh38.primary_assembly.genome.fa.1.bt2 #>   BFC4   | GRCh38.primary_assembly.genome.fa.2.bt2 #>   BFC5   | GRCh38.primary_assembly.genome.fa.3.bt2 #>   ...      ...                                     #>   BFC127 | knownGene_mm39.sql                      #>   BFC128 | knownGene_mm39.txt                      #>   BFC129 | refGene_mm39.sql                        #>   BFC130 | refGene_mm39.txt                        #>   BFC131 | GRCh37_to_GRCh38.chain                  #>          Path                                                                #>   BFC1   /tmp/RtmpXMx6sd/SharedData/outfile.txt                              #>   BFC2   /tmp/RtmpXMx6sd/exp_data                                            #>   BFC3   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC4   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   BFC5   https://storage.googleapis.com/reusedata/bowtie2_index/GRCh38.pr... #>   ...    ...                                                                 #>   BFC127 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC128 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC129 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC130 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC131 /tmp/RtmpXMx6sd/gcpData/GRCh37_to_GRCh38.chain"},{"path":"/articles/ReUseData_data.html","id":"know-your-data","dir":"Articles","previous_headings":"","what":"Know your data","title":"ReUseData: Reusable and Reproducible Data Management","text":"provide function meta_data() create data frame contains information data sets specified file path (recursively), including annotation file ($yml column), parameter values recipe ($params column), data file path ($output column), keywords data file (notes columns), date data generation (date column), tag available (tag column). Use cleanup = TRUE cleanup invalid expired/older intermediate files.","code":"mt <- meta_data(outdir) head(mt) #>                                                            yml #> 1 /tmp/RtmpXMx6sd/SharedData/echo_out_Hello_World!_outfile.yml #>                                  params                                 output #> 1 input: Hello World!; outfile: outfile /tmp/RtmpXMx6sd/SharedData/outfile.txt #>                  notes                       date #> 1 echo hello world txt 2023-11-22 22:21:02.021824"},{"path":"/articles/ReUseData_data.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"ReUseData: Reusable and Reproducible Data Management","text":"","code":"sessionInfo() #> R version 4.3.1 (2023-06-16) #> Platform: x86_64-conda-linux-gnu (64-bit) #> Running under: Ubuntu 22.04.3 LTS #>  #> Matrix products: default #> BLAS/LAPACK: /home/qhu/miniconda3/envs/rcwl/lib/libopenblasp-r0.3.23.so;  LAPACK version 3.11.0 #>  #> locale: #>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               #>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     #>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    #>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  #>  [9] LC_ADDRESS=C               LC_TELEPHONE=C             #> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C        #>  #> time zone: America/New_York #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats4    stats     graphics  grDevices utils     datasets  methods   #> [8] base      #>  #> other attached packages: #> [1] ReUseData_1.3.2     Rcwl_1.18.0         S4Vectors_0.40.1    #> [4] BiocGenerics_0.48.1 yaml_2.3.7          BiocStyle_2.30.0    #>  #> loaded via a namespace (and not attached): #>  [1] tidyselect_1.2.0      dplyr_1.1.4           blob_1.2.4            #>  [4] filelock_1.0.2        R.utils_2.12.3        fastmap_1.1.1         #>  [7] BiocFileCache_2.10.1  promises_1.2.1        digest_0.6.33         #> [10] base64url_1.4         mime_0.12             lifecycle_1.0.4       #> [13] ellipsis_0.3.2        RSQLite_2.3.3         magrittr_2.0.3        #> [16] compiler_4.3.1        rlang_1.1.2           sass_0.4.7            #> [19] progress_1.2.2        tools_4.3.1           utf8_1.2.4            #> [22] data.table_1.14.8     knitr_1.45            prettyunits_1.2.0     #> [25] brew_1.0-8            htmlwidgets_1.6.2     curl_5.1.0            #> [28] bit_4.0.5             reticulate_1.34.0     RColorBrewer_1.1-3    #> [31] batchtools_0.9.17     BiocParallel_1.36.0   withr_2.5.2           #> [34] purrr_1.0.2           desc_1.4.2            R.oo_1.25.0           #> [37] grid_4.3.1            fansi_1.0.5           git2r_0.32.0          #> [40] xtable_1.8-4          cli_3.6.1             rmarkdown_2.25        #> [43] DiagrammeR_1.0.10     crayon_1.5.2          ragg_1.2.5            #> [46] generics_0.1.3        httr_1.4.7            visNetwork_2.1.2      #> [49] DBI_1.1.3             cachem_1.0.8          stringr_1.5.1         #> [52] parallel_4.3.1        BiocManager_1.30.22   basilisk_1.14.1       #> [55] vctrs_0.6.4           Matrix_1.6-3          jsonlite_1.8.7        #> [58] dir.expiry_1.10.0     bookdown_0.36         hms_1.1.3             #> [61] bit64_4.0.5           systemfonts_1.0.4     jquerylib_0.1.4       #> [64] RcwlPipelines_1.18.0  glue_1.6.2            pkgdown_2.0.7         #> [67] codetools_0.2-19      stringi_1.8.1         later_1.3.1           #> [70] tibble_3.2.1          pillar_1.9.0          basilisk.utils_1.14.1 #> [73] rappdirs_0.3.3        htmltools_0.5.7       R6_2.5.1              #> [76] dbplyr_2.4.0          textshaping_0.3.6     rprojroot_2.0.4       #> [79] evaluate_0.23         shiny_1.8.0           lattice_0.22-5        #> [82] R.methodsS3_1.8.2     png_0.1-8             backports_1.4.1       #> [85] memoise_2.0.1         httpuv_1.6.12         bslib_0.5.1           #> [88] Rcpp_1.0.11           checkmate_2.3.0       xfun_0.41             #> [91] fs_1.6.3              pkgconfig_2.0.3"},{"path":"/articles/ReUseData_quickStart.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"ReUseData R/Bioconductor software tool provide systematic versatile approach standardized reproducible data management. ReUseData facilitates transformation shell ad hoc scripts data preprocessing workflow-based data recipes. Evaluation data recipes generate curated data files generic formats (e.g., VCF, bed). recipes data cached using database infrastructure easy data management reuse. Prebuilt data recipes available ReUseData portal (“https://rcwl.org/dataRecipes/”) full annotation user instructions. Pregenerated data available ReUseData cloud bucket directly downloadable “getCloudData()”. quick start shows basic use package functions 2 major categories managing: Data recipes Reusable data Details section can found companion vignettes data recipes reusable data.","code":""},{"path":"/articles/ReUseData_quickStart.html","id":"package-installation-and-loading","dir":"Articles","previous_headings":"","what":"Package installation and loading","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"BiocManager::install(c(\"ReUseData\", \"Rcwl\")) library(ReUseData)"},{"path":"/articles/ReUseData_quickStart.html","id":"data-recipes","dir":"Articles","previous_headings":"","what":"Data recipes","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"pre-built data recipes included package can easily updated (recipeUpdate), searched (recipeSearch) loaded (recipeLoad). Details data recipes can found vignette ReUseData_recipe.html.","code":""},{"path":"/articles/ReUseData_quickStart.html","id":"search-and-load-a-data-recipe","dir":"Articles","previous_headings":"Data recipes","what":"Search and load a data recipe","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"recipeUpdate(cachePath = \"ReUseDataRecipe\", force = TRUE) #> NOTE: existing caches will be removed and regenerated! #> Updating recipes... #> bowtie2_index.R added #> echo_out.R added #> ensembl_liftover.R added #> gcp_broad_gatk_hg19.R added #> gcp_broad_gatk_hg38.R added #> gcp_gatk_mutect2_b37.R added #> gcp_gatk_mutect2_hg38.R added #> gencode_annotation.R added #> gencode_genome_grch38.R added #> gencode_transcripts.R added #> hisat2_index.R added #> reference_genome.R added #> salmon_index.R added #> STAR_index.R added #> ucsc_database.R added #>  #> recipeHub with 15 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                #>   BFC481 | bowtie2_index       #>   BFC482 | echo_out            #>   BFC483 | ensembl_liftover    #>   BFC484 | gcp_broad_gatk_hg19 #>   BFC485 | gcp_broad_gatk_hg38 #>   ...      ...                 #>   BFC491 | hisat2_index        #>   BFC492 | reference_genome    #>   BFC493 | salmon_index        #>   BFC494 | STAR_index          #>   BFC495 | ucsc_database recipeSearch(\"echo\") #> recipeHub with 1 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name     #>   BFC482 | echo_out echo_out <- recipeLoad(\"echo_out\") #> Note: you need to assign a name for the recipe: rcpName <- recipeLoad('xx') #> Data recipe loaded! #> Use inputs() to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/echo_out.html #> for user instructions (e.g., eligible input values, data source, etc.)"},{"path":"/articles/ReUseData_quickStart.html","id":"evaluate-a-data-recipe","dir":"Articles","previous_headings":"Data recipes","what":"Evaluate a data recipe","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"can install cwltool first make sure cwl-runner available. data recipe can evaluated assigning values recipe parameters. getData runs recipe CWL scripts internally, generates data interest annotation files future reuse.","code":"invisible(Rcwl::install_cwltool()) Rcwl::inputs(echo_out) #> inputs: #>   input (input)  (string):   #>   outfile (outfile)  (string): echo_out$input <- \"Hello World!\" echo_out$outfile <- \"outfile\" outdir <- file.path(tempdir(), \"SharedData\") res <- getData(echo_out,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\")) #> }INFO Final process status is success res$out #> [1] \"/tmp/RtmpKPz1uV/SharedData/outfile.txt\" readLines(res$out) #> [1] \"Print the input: Hello World!\""},{"path":"/articles/ReUseData_quickStart.html","id":"create-your-own-data-recipes","dir":"Articles","previous_headings":"Data recipes","what":"Create your own data recipes","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"One can create data recipe scratch converting existing shell script data processing, specifying input parameters, output globbing patterns using recipeMake function.","code":"script <- system.file(\"extdata\", \"echo_out.sh\", package = \"ReUseData\") rcp <- recipeMake(shscript = script,                   paramID = c(\"input\", \"outfile\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"echoout\",                   outputGlob = \"*.txt\") Rcwl::inputs(rcp) #> inputs: #>   input (string):   #>   outfile (string): Rcwl::outputs(rcp) #> outputs: #> echoout: #>   type: File[] #>   outputBinding: #>     glob: '*.txt'"},{"path":"/articles/ReUseData_quickStart.html","id":"reusable-data","dir":"Articles","previous_headings":"","what":"Reusable data","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"data generated evaluating data recipes automatically annotated tracked user-specified keywords time/date tags. uses similar cache system recipes users easily update (dataUpdate), search (dataSearch) use (toList). Pre-generated data files existing data recipes saved Google Cloud Bucket, ready queried (dataSearch(cloud=TRUE)) downloaded (getCloudData) local cache system annotations.","code":""},{"path":"/articles/ReUseData_quickStart.html","id":"update-data-files-that-are-generated-using-reusedata","dir":"Articles","previous_headings":"Reusable data","what":"Update data files that are generated using ReUseData","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"dh <- dataUpdate(dir = outdir) dataSearch(c(\"echo\", \"hello\")) dataNames(dh) dataParams(dh) dataNotes(dh)"},{"path":"/articles/ReUseData_quickStart.html","id":"export-data-into-workflow-ready-files","dir":"Articles","previous_headings":"Reusable data","what":"Export data into workflow-ready files","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"toList(dh, format=\"json\", file = file.path(outdir, \"data.json\"))"},{"path":"/articles/ReUseData_quickStart.html","id":"download-pregenerated-data-from-google-cloud","dir":"Articles","previous_headings":"Reusable data","what":"Download pregenerated data from Google Cloud","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"dh <- dataUpdate(dir = outdir, cloud = TRUE) getCloudData(dh[2], outdir = outdir)"},{"path":"/articles/ReUseData_quickStart.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"ReUseData: Reusable and Reproducible Data Management - quick start","text":"","code":"sessionInfo() #> R version 4.3.1 (2023-06-16) #> Platform: x86_64-conda-linux-gnu (64-bit) #> Running under: Ubuntu 22.04.3 LTS #>  #> Matrix products: default #> BLAS/LAPACK: /home/qhu/miniconda3/envs/rcwl/lib/libopenblasp-r0.3.23.so;  LAPACK version 3.11.0 #>  #> locale: #>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               #>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     #>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    #>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  #>  [9] LC_ADDRESS=C               LC_TELEPHONE=C             #> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C        #>  #> time zone: America/New_York #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] ReUseData_1.3.2  BiocStyle_2.30.0 #>  #> loaded via a namespace (and not attached): #>  [1] tidyselect_1.2.0      dplyr_1.1.4           blob_1.2.4            #>  [4] filelock_1.0.2        R.utils_2.12.3        fastmap_1.1.1         #>  [7] BiocFileCache_2.10.1  promises_1.2.1        digest_0.6.33         #> [10] base64url_1.4         mime_0.12             lifecycle_1.0.4       #> [13] ellipsis_0.3.2        Rcwl_1.18.0           RSQLite_2.3.3         #> [16] magrittr_2.0.3        compiler_4.3.1        rlang_1.1.2           #> [19] sass_0.4.7            progress_1.2.2        tools_4.3.1           #> [22] utf8_1.2.4            yaml_2.3.7            data.table_1.14.8     #> [25] knitr_1.45            prettyunits_1.2.0     brew_1.0-8            #> [28] htmlwidgets_1.6.2     bit_4.0.5             curl_5.1.0            #> [31] reticulate_1.34.0     RColorBrewer_1.1-3    batchtools_0.9.17     #> [34] BiocParallel_1.36.0   withr_2.5.2           purrr_1.0.2           #> [37] BiocGenerics_0.48.1   desc_1.4.2            R.oo_1.25.0           #> [40] grid_4.3.1            stats4_4.3.1          fansi_1.0.5           #> [43] git2r_0.32.0          xtable_1.8-4          cli_3.6.1             #> [46] rmarkdown_2.25        DiagrammeR_1.0.10     crayon_1.5.2          #> [49] ragg_1.2.5            generics_0.1.3        httr_1.4.7            #> [52] visNetwork_2.1.2      DBI_1.1.3             cachem_1.0.8          #> [55] stringr_1.5.1         parallel_4.3.1        BiocManager_1.30.22   #> [58] basilisk_1.14.1       vctrs_0.6.4           Matrix_1.6-3          #> [61] jsonlite_1.8.7        dir.expiry_1.10.0     bookdown_0.36         #> [64] hms_1.1.3             S4Vectors_0.40.1      bit64_4.0.5           #> [67] systemfonts_1.0.4     jquerylib_0.1.4       RcwlPipelines_1.18.0  #> [70] glue_1.6.2            pkgdown_2.0.7         codetools_0.2-19      #> [73] stringi_1.8.1         later_1.3.1           tibble_3.2.1          #> [76] pillar_1.9.0          basilisk.utils_1.14.1 rappdirs_0.3.3        #> [79] htmltools_0.5.7       R6_2.5.1              dbplyr_2.4.0          #> [82] textshaping_0.3.6     rprojroot_2.0.4       lattice_0.22-5        #> [85] evaluate_0.23         shiny_1.8.0           png_0.1-8             #> [88] R.methodsS3_1.8.2     backports_1.4.1       memoise_2.0.1         #> [91] httpuv_1.6.12         bslib_0.5.1           Rcpp_1.0.11           #> [94] checkmate_2.3.0       xfun_0.41             fs_1.6.3              #> [97] pkgconfig_2.0.3"},{"path":"/articles/ReUseData_recipe.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"growth volume complexity genomic data resources past decades poses opportunities challenges data reuse. Presently, reuse data often involves similar preprocessing steps different research projects. Lack standardized annotation strategy can lead difficult--find even duplicated datasets, resulting substantial inefficiencies wasted computing resources, especially research collaborations bioinformatics core facilities. Tools GoGetData AnnotationHub developed mitigate common problems managing accessing curated genomic datasets. However, use can limited due software requirements (e.g., Conda https://conda.io), forms data representation scope data resources. respond FAIR (findability, accessibility, interoperability, reusability) data principles widely adopted organizational requirements Data Management Plans (DMPs), , introduce ReUseData, R/Bioconductor software tool provide systematic versatile approach standardized reproducible data management. ReUseData facilitates transformation shell ad hoc scripts data preprocessing workflow-based data recipes. Evaluation data recipes generate curated data files generic formats (e.g., VCF, bed) full annotations subsequent reuse. package focuses management genomic data resources uses classes functions existing Bioconductor packages. think good fit Bioconductor.","code":""},{"path":"/articles/ReUseData_recipe.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"Install package Bioconductor. Use development version: Load package packages used vignette R session.","code":"if (!requireNamespace(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\") BiocManager::install(\"ReUseData\") BiocManager::install(\"ReUseData\", version = \"devel\") suppressPackageStartupMessages(library(Rcwl)) library(ReUseData)"},{"path":[]},{"path":"/articles/ReUseData_recipe.html","id":"reusedata-recipe-landing-pages","dir":"Articles","previous_headings":"Project resources","what":"ReUseData recipe landing pages","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"project website https://rcwl.org/dataRecipes/ contains prebuilt data recipes public data downloading curation. available direct use convenient webpage searching. data recipe landing page including recipe description (inputs, outputs, etc.) user instructions. Make sure check instructions eligible input parameter values recipe evaluation. prebuilt data recipes demonstrate use software can taken templates users create recipes protected datasets. many R resources available main website https://rcwl.org/, including package vignettes Rcwl andRcwlPipelines, Rcwl tutorial e-book, case studies using RcwlPipelines preprocessing single-cell RNA-seq data, etc.","code":""},{"path":"/articles/ReUseData_recipe.html","id":"reusedata-recipe-scripts","dir":"Articles","previous_headings":"","what":"ReUseData recipe scripts","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"prebuilt data recipe scripts included package, physically residing dedicated GitHub repository, demonstrates recipe construction different situations. common case data recipe can manage multiple data resources different input parameters (species, versions, etc.). example, gencode_transcripts recipe download GENCODE, unzip index transcript fasta file human mouse different versions. simple data downloading (using wget) specific file can written data recipe without input parameter. example, data recipe gcp_broad_gatk_hg38_1000G_omni2.5) downloads 1000G_omni2.5.hg38.vcf.gz tbi index files Google Cloud Platform bucket Broad reference data GATK hg38. data curation gets complicated, say, multiple command-line tools involved, conda can used install required packages, secondary files generated collected, raw way building ReUseData recipe using Rcwl functions recommended, gives flexibility power accommodate different situations. example recipe reference_genome downloads, formats, index reference genome data using tools samtools, picard bwa, manages multiple secondary files besides main fasta file later reuse.","code":""},{"path":"/articles/ReUseData_recipe.html","id":"reusedata-core-functions","dir":"Articles","previous_headings":"","what":"ReUseData core functions","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"show usage 4 core functions recipeMake, recipeUpdate, recipeSearch, recipeLoad constructing, updating, searching loading ReUseData recipes R.","code":""},{"path":"/articles/ReUseData_recipe.html","id":"recipe-construction-and-evaluation","dir":"Articles","previous_headings":"ReUseData core functions","what":"Recipe construction and evaluation","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"One can construct data recipe scratch convert existing shell scripts data processing data recipes, specifying input parameters, output globbing patterns using recipeMake function. data recipe represented R S4 class cwlProcess. Upon assigning values input parameters, recipe ready evaluated generate data interest. two examples: Equivalently, can load shell script directly: Evaluation data recipes internally submitted CWL workflow tasks, requires latest version cwltool. used basilisk initiate conda environment install cwltool environment available (older versions available) computer system. can install cwltool first make sure cwl-runner available. Let’s take look output file, successfully generated user-specified directory grabbed outputGlob argument. details getData function recipe evaluation, check vignette reusable data management. show complex example shell script required command line tools. specific tools needed data processing, users just need add names requireTools argument recipeMake function, add conda = TRUE evaluating recipe getData function. tools automatically installed initiating conda environment script can successfully run environment. function promotes data reproducibility across different computing platforms, removes barrier using sophisticated bioinformatics tools less experienced users. following code chunk evaluated time-limit package building can evaluated users.","code":"script <- ' input=$1 outfile=$2 echo \"Print the input: $input\" > $outfile.txt ' script <- system.file(\"extdata\", \"echo_out.sh\", package = \"ReUseData\") rcp <- recipeMake(shscript = script,                   paramID = c(\"input\", \"outfile\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"echoout\",                   outputGlob = \"*.txt\") inputs(rcp) #> inputs: #>   input (string):   #>   outfile (string): outputs(rcp) #> outputs: #> echoout: #>   type: File[] #>   outputBinding: #>     glob: '*.txt' invisible(Rcwl::install_cwltool()) rcp$input <- \"Hello World!\" rcp$outfile <- \"outfile\" outdir <- file.path(tempdir(), \"SharedData\") res <- getData(rcp,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\")) #> }INFO Final process status is success res$out #> [1] \"/tmp/RtmpGKcx5v/SharedData/outfile.txt\" readLines(res$out) #> [1] \"Print the input: Hello World!\" shfile <- system.file(\"extdata\", \"gencode_transcripts.sh\",                       package = \"ReUseData\") readLines(shfile) rcp <- recipeMake(shscript = shfile,                   paramID = c(\"species\", \"version\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"transcripts\",                    outputGlob = \"*.transcripts.fa*\",                   requireTools = c(\"wget\", \"gzip\", \"samtools\")                   ) rcp$species <- \"human\" rcp$version <- \"42\" res <- getData(rcp,         outdir = outdir,         notes = c(\"gencode\", \"transcripts\", \"human\", \"42\"),         conda = TRUE) res$output"},{"path":"/articles/ReUseData_recipe.html","id":"recipe-caching-and-updating","dir":"Articles","previous_headings":"ReUseData core functions","what":"Recipe caching and updating","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"recipeUpdate() creates local cache data recipes saved specified GitHub repository (first time use), syncs updates data recipes GitHub repo local caching system, newly added recipes can readily accessed loaded directly R. NOTE: cachePath argument need match recipeUpdate, recipeLoad recipeSearch functions. use force=TRUE old recipes previously cached updated. use remote = TRUEto sync remote GitHub repositories. default, syncs ReUseDataRecipe GitHub repository](https://github.com/rworkflow/ReUseDataRecipe) public, prebuilt data recipes. repo can also private GitHub repository. sync local recipe cache remote GitHub repository. Currently remote data recipes GitHub recipes package (evaluted avoid duplicate messages). best keep current data recipes package development version remote GitHub repository. recipeUpdate returns recipeHub object list available recipes. One can subset list [ use getter functions recipeNames() get recipe names can passed recipeSearch() recipeLoad().","code":"## First time use recipeUpdate(cachePath = \"ReUseDataRecipe\",              force = TRUE) #> NOTE: existing caches will be removed and regenerated! #> Updating recipes... #> bowtie2_index.R added #> echo_out.R added #> ensembl_liftover.R added #> gcp_broad_gatk_hg19.R added #> gcp_broad_gatk_hg38.R added #> gcp_gatk_mutect2_b37.R added #> gcp_gatk_mutect2_hg38.R added #> gencode_annotation.R added #> gencode_genome_grch38.R added #> gencode_transcripts.R added #> hisat2_index.R added #> reference_genome.R added #> salmon_index.R added #> STAR_index.R added #> ucsc_database.R added #>  #> recipeHub with 15 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                #>   BFC496 | bowtie2_index       #>   BFC497 | echo_out            #>   BFC498 | ensembl_liftover    #>   BFC499 | gcp_broad_gatk_hg19 #>   BFC500 | gcp_broad_gatk_hg38 #>   ...      ...                 #>   BFC506 | hisat2_index        #>   BFC507 | reference_genome    #>   BFC508 | salmon_index        #>   BFC509 | STAR_index          #>   BFC510 | ucsc_database recipeUpdate(remote = TRUE,              repos = \"rworkflow/ReUseDataRecipe\")  ## can be private repo rh <- recipeUpdate() #> Updating recipes... #>  is(rh) #> [1] \"recipeHub\"             \"cwlHub\"                \"BiocFileCacheReadOnly\" #> [4] \"BiocFileCacheBase\" rh[1] #> recipeHub with 1 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name          #>   BFC496 | bowtie2_index recipeNames(rh) #>  [1] \"bowtie2_index\"         \"echo_out\"              \"ensembl_liftover\"      #>  [4] \"gcp_broad_gatk_hg19\"   \"gcp_broad_gatk_hg38\"   \"gcp_gatk_mutect2_b37\"  #>  [7] \"gcp_gatk_mutect2_hg38\" \"gencode_annotation\"    \"gencode_genome_grch38\" #> [10] \"gencode_transcripts\"   \"hisat2_index\"          \"reference_genome\"      #> [13] \"salmon_index\"          \"STAR_index\"            \"ucsc_database\""},{"path":"/articles/ReUseData_recipe.html","id":"recipe-searching-and-loading","dir":"Articles","previous_headings":"ReUseData core functions","what":"Recipe searching and loading","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"Cached data recipes can searched using multiple keywords match recipe name. returns recipeHub object list recipes available. Recipes can directly loaded R using recipeLoad function user assigned name original recipe name. recipe successfully loaded, message returned recipe instructions. NOTE Use return=FALSE want keep original recipe name, multiple recipes loaded. ’s important check required inputs() recipe recipe landing page eligible input parameter values evaluating recipe generate data interest.","code":"recipeSearch() #> recipeHub with 15 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                #>   BFC496 | bowtie2_index       #>   BFC497 | echo_out            #>   BFC498 | ensembl_liftover    #>   BFC499 | gcp_broad_gatk_hg19 #>   BFC500 | gcp_broad_gatk_hg38 #>   ...      ...                 #>   BFC506 | hisat2_index        #>   BFC507 | reference_genome    #>   BFC508 | salmon_index        #>   BFC509 | STAR_index          #>   BFC510 | ucsc_database recipeSearch(\"gencode\") #> recipeHub with 3 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                  #>   BFC503 | gencode_annotation    #>   BFC504 | gencode_genome_grch38 #>   BFC505 | gencode_transcripts recipeSearch(c(\"STAR\", \"index\")) #> recipeHub with 1 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name       #>   BFC509 | STAR_index rcp <- recipeLoad(\"STAR_index\") #> Note: you need to assign a name for the recipe: rcpName <- recipeLoad('xx') #> Data recipe loaded! #> Use inputs() to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/STAR_index.html #> for user instructions (e.g., eligible input values, data source, etc.) recipeLoad(\"STAR_index\", return = FALSE) #> Data recipe loaded! #> Use inputs(STAR_index) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/STAR_index.html #> for user instructions (e.g., eligible input values, data source, etc.) identical(rcp, STAR_index) #> [1] TRUE recipeLoad(c(\"ensembl_liftover\", \"gencode_annotation\"), return=FALSE) #> Data recipe loaded! #> Use inputs(ensembl_liftover) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/ensembl_liftover.html #> for user instructions (e.g., eligible input values, data source, etc.) #> Data recipe loaded! #> Use inputs(gencode_annotation) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/gencode_annotation.html #> for user instructions (e.g., eligible input values, data source, etc.) inputs(STAR_index) #> inputs: #>   ref (reference genome)   ( string|File ):  #>   gtf (GTF)   ( string|File ):  #>   genomeDir (genomeDir)  (string):   #>   threads (threads)  (int):   #>   sjdb (sjdbOverhang)  (int):  100 inputs(ensembl_liftover) #> inputs: #>   species (species)  (string):   #>   from (from)  (string):   #>   to (to)  (string): inputs(gencode_annotation) #> inputs: #>   species (species)  (string):   #>   version (version)  (string):"},{"path":"/articles/ReUseData_recipe.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"ReUseData: Workflow-based Data Recipes for Management of Reusable and Reproducible Data Resources","text":"","code":"sessionInfo() #> R version 4.3.1 (2023-06-16) #> Platform: x86_64-conda-linux-gnu (64-bit) #> Running under: Ubuntu 22.04.3 LTS #>  #> Matrix products: default #> BLAS/LAPACK: /home/qhu/miniconda3/envs/rcwl/lib/libopenblasp-r0.3.23.so;  LAPACK version 3.11.0 #>  #> locale: #>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               #>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     #>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    #>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  #>  [9] LC_ADDRESS=C               LC_TELEPHONE=C             #> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C        #>  #> time zone: America/New_York #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats4    stats     graphics  grDevices utils     datasets  methods   #> [8] base      #>  #> other attached packages: #> [1] ReUseData_1.3.2     Rcwl_1.18.0         S4Vectors_0.40.1    #> [4] BiocGenerics_0.48.1 yaml_2.3.7          BiocStyle_2.30.0    #>  #> loaded via a namespace (and not attached): #>  [1] tidyselect_1.2.0      dplyr_1.1.4           blob_1.2.4            #>  [4] filelock_1.0.2        R.utils_2.12.3        fastmap_1.1.1         #>  [7] BiocFileCache_2.10.1  promises_1.2.1        digest_0.6.33         #> [10] base64url_1.4         mime_0.12             lifecycle_1.0.4       #> [13] ellipsis_0.3.2        RSQLite_2.3.3         magrittr_2.0.3        #> [16] compiler_4.3.1        rlang_1.1.2           sass_0.4.7            #> [19] progress_1.2.2        tools_4.3.1           utf8_1.2.4            #> [22] data.table_1.14.8     knitr_1.45            prettyunits_1.2.0     #> [25] brew_1.0-8            htmlwidgets_1.6.2     curl_5.1.0            #> [28] bit_4.0.5             reticulate_1.34.0     RColorBrewer_1.1-3    #> [31] batchtools_0.9.17     BiocParallel_1.36.0   withr_2.5.2           #> [34] purrr_1.0.2           desc_1.4.2            R.oo_1.25.0           #> [37] grid_4.3.1            fansi_1.0.5           git2r_0.32.0          #> [40] xtable_1.8-4          cli_3.6.1             rmarkdown_2.25        #> [43] DiagrammeR_1.0.10     crayon_1.5.2          ragg_1.2.5            #> [46] generics_0.1.3        httr_1.4.7            visNetwork_2.1.2      #> [49] DBI_1.1.3             cachem_1.0.8          stringr_1.5.1         #> [52] parallel_4.3.1        BiocManager_1.30.22   basilisk_1.14.1       #> [55] vctrs_0.6.4           Matrix_1.6-3          jsonlite_1.8.7        #> [58] dir.expiry_1.10.0     bookdown_0.36         hms_1.1.3             #> [61] bit64_4.0.5           systemfonts_1.0.4     jquerylib_0.1.4       #> [64] RcwlPipelines_1.18.0  glue_1.6.2            pkgdown_2.0.7         #> [67] codetools_0.2-19      stringi_1.8.1         later_1.3.1           #> [70] tibble_3.2.1          pillar_1.9.0          basilisk.utils_1.14.1 #> [73] rappdirs_0.3.3        htmltools_0.5.7       R6_2.5.1              #> [76] dbplyr_2.4.0          textshaping_0.3.6     rprojroot_2.0.4       #> [79] evaluate_0.23         shiny_1.8.0           lattice_0.22-5        #> [82] R.methodsS3_1.8.2     png_0.1-8             backports_1.4.1       #> [85] memoise_2.0.1         httpuv_1.6.12         bslib_0.5.1           #> [88] Rcpp_1.0.11           checkmate_2.3.0       xfun_0.41             #> [91] fs_1.6.3              pkgconfig_2.0.3"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Qian Liu. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liu Q (2023). ReUseData: Reusable reproducible Data Management. R package version 1.3.2, https://github.com/rworkflow/ReUseData.","code":"@Manual{,   title = {ReUseData: Reusable and reproducible Data Management},   author = {Qian Liu},   year = {2023},   note = {R package version 1.3.2},   url = {https://github.com/rworkflow/ReUseData}, }"},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Reusable and reproducible Data Management","title":"Reusable and reproducible Data Management","text":"ReUseData R/Bioconductor software tool provide systematic versatile approach standardized reproducible data management. ReUseData facilitates transformation shell ad hoc scripts data preprocessing workflow-based data recipes. Evaluation data recipes generate curated data files generic formats (e.g., VCF, bed). recipes data cached using database infrastructure easy data management reuse. Prebuilt data recipes available ReUseData portal (“https://rcwl.org/dataRecipes/”) full annotation user instructions. Pregenerated data available ReUseData cloud bucket directly downloadable “getCloudData()”. quick start shows basic use package functions 2 major categories managing: Data recipes Reusable data Details section can found vignettes ReUseData_recipe.html ReUseData_data.html.","code":""},{"path":"/index.html","id":"package-installation","dir":"","previous_headings":"","what":"Package installation","title":"Reusable and reproducible Data Management","text":"","code":"BiocManager::install(c(\"ReUseData\", \"Rcwl\")) library(ReUseData)"},{"path":"/index.html","id":"data-recipes","dir":"","previous_headings":"","what":"Data recipes","title":"Reusable and reproducible Data Management","text":"pre-built data recipes included package can easily updated (recipeUpdate), searched (recipeSearch) loaded (recipeLoad). Details data recipes can found vignette ReUseData_recipe.html.","code":""},{"path":"/index.html","id":"search-and-load-a-data-recipe","dir":"","previous_headings":"","what":"Search and load a data recipe","title":"Reusable and reproducible Data Management","text":"","code":"recipeUpdate(cachePath = \"ReUseDataRecipe\", force = TRUE) recipeSearch(\"echo\") recipeLoad(\"echo_out\", return = TRUE)"},{"path":"/index.html","id":"evaluate-a-data-recipe","dir":"","previous_headings":"","what":"Evaluate a data recipe","title":"Reusable and reproducible Data Management","text":"data recipe can evaluated assigning values recipe parameters. getData runs recipe CWL scripts internally, generates data interest annotation files future reuse.","code":"Rcwl::inputs(echo_out) echo_out$input <- \"Hello World!\" echo_out$outfile <- \"outfile\" outdir <- file.path(tempdir(), \"SharedData\") res <- getData(echo_out,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\")) res$out readLines(res$out)"},{"path":"/index.html","id":"create-your-own-data-recipes","dir":"","previous_headings":"","what":"Create your own data recipes","title":"Reusable and reproducible Data Management","text":"One can create data recipe scratch converting existing shell script data processing, specifying input parameters, output globbing patterns using recipeMake function.","code":"script <- system.file(\"extdata\", \"echo_out.sh\", package = \"ReUseData\") rcp <- recipeMake(shscript = script,                   paramID = c(\"input\", \"outfile\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"echoout\",                   outputGlob = \"*.txt\") Rcwl::inputs(rcp) Rcwl::outputs(rcp)"},{"path":"/index.html","id":"reusable-data","dir":"","previous_headings":"","what":"Reusable data","title":"Reusable and reproducible Data Management","text":"data generated evaluating data recipes automatically annotated tracked user-specified keywords time/date tags. uses similar cache system recipes users easily update (dataUpdate), search (dataSearch) use (toList). Pre-generated data files existing data recipes saved Google Cloud Bucket, ready queried (dataSearch(cloud=TRUE)) downloaded (getCloudData) local cache system annotations.","code":""},{"path":"/index.html","id":"update-data-files-that-are-generated-using-reusedata","dir":"","previous_headings":"","what":"Update data files that are generated using ReUseData","title":"Reusable and reproducible Data Management","text":"","code":"dh <- dataUpdate(dir = outdir) dataSearch(c(\"echo\", \"hello\")) dataNames(dh) dataParams(dh) dataNotes(dh)"},{"path":"/index.html","id":"export-data-into-workflow-ready-files","dir":"","previous_headings":"","what":"Export data into workflow-ready files","title":"Reusable and reproducible Data Management","text":"","code":"toList(dh, format=\"json\", file = file.path(outdir, \"data.json\"))"},{"path":"/index.html","id":"download-pregenerated-data-from-google-cloud","dir":"","previous_headings":"","what":"Download pregenerated data from Google Cloud","title":"Reusable and reproducible Data Management","text":"","code":"dh <- dataUpdate(dir = outdir, cloud = TRUE) getCloudData(dh[2], outdir = outdir)"},{"path":"/reference/ReUseData-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ReUseData — ReUseData","title":"ReUseData — ReUseData","text":"ReUseData R/Bioconductor software tool provide systematic versatile approach standardized reproducible data management. ReUseData facilitates transformation shell ad hoc scripts data preprocessing workflow-based data recipes. Evaluation data recipes generate curated data files generic formats (e.g., VCF, bed). recipes data cached using database infrastructure easy data management reuse. Prebuilt data recipes available ReUseData portal (\"https://rcwl.org/dataRecipes/\") full annotation user instructions. Pregenerated data available ReUseData cloud bucket directly downloadable \"getCloudData()\".","code":""},{"path":"/reference/annData.html","id":null,"dir":"Reference","previous_headings":"","what":"annData — annData","title":"annData — annData","text":"Add annotation meta information existing data","code":""},{"path":"/reference/annData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"annData — annData","text":"","code":"annData(   path,   notes,   date = Sys.Date(),   recursive = TRUE,   md5 = FALSE,   skip = \"*.md|meta.yml\",   force = FALSE,   ... )"},{"path":"/reference/annData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"annData — annData","text":"path data path annotate. notes User assigned notes/keywords annotate data used keywords matching dataSearch(keywords = ). date date data. recursive Whether annotate data recursively. md5 Whether generate md5 values files. skip Patter skip files path. force Whether force regenerate meta.yml. ... options list.files","code":""},{"path":"/reference/dataHub-class.html","id":null,"dir":"Reference","previous_headings":"","what":"dataHub Class — dataHub","title":"dataHub Class — dataHub","text":"dataHub class, constructor, methods.","code":""},{"path":"/reference/dataHub-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataHub Class — dataHub","text":"","code":"dataHub(BFC)  dataHub(BFC)  # S4 method for dataHub show(object)  dataNames(object)  dataParams(object)  dataNotes(object)  dataPaths(object)  dataYml(object)  dataTags(object)  # S4 method for dataHub dataTags(object)  dataTags(object, append = TRUE) <- value  # S4 method for dataHub dataTags(object, append = FALSE) <- value  # S4 method for dataHub,ANY,ANY,ANY [(x, i, j, drop)  # S4 method for dataHub,ANY,ANY,ANY [(x, i, j) <- value  # S4 method for dataHub c(x, ...)  toList(   x,   listNames = NULL,   format = c(\"list\", \"json\", \"yaml\"),   type = NULL,   file = character() )"},{"path":"/reference/dataHub-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataHub Class — dataHub","text":"BFC BiocFileCache object created data recipes. object dataHub object. append Whether append new tag replace tags. value dataHub object x dataHub object. integer index dataHub object, logical vector length dataHub object. j inherited [ generic. drop Inherited [ generic. ... dataHub objects combine. listNames vector names output list. format can \"list\", \"json\" \"yaml\". Supports partial match. Default list. type type workflow input list, cwl. file file name save data list required format. data extension needs included, e.g., \".json\" \".yml\".","code":""},{"path":"/reference/dataHub-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataHub Class — dataHub","text":"dataHub: dataHub object. dataNames: names datasets dataHub object. dataParams: data recipe parameter values datasets dataHub object. dataNotes: notes datasets dataHub object. dataPaths: file paths datasets dataHub object. dataYml: yaml file paths datasets dataHub object. dataTags: tags datasets dataHub object. toList: list datasets specific format, file file argument specified.","code":""},{"path":"/reference/dataHub-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataHub Class — dataHub","text":"","code":"outdir <- file.path(tempdir(), \"SharedData\") dataUpdate(outdir, cloud = TRUE) #>  #> Updating data record... #> 35c86a4f3633_GRCh38.primary_assembly.genome.fa.1.bt2 added #> 35c86144ba7c7_GRCh38.primary_assembly.genome.fa.2.bt2 added #> 35c8611076c9_GRCh38.primary_assembly.genome.fa.3.bt2 added #> 35c8673a08e08_GRCh38.primary_assembly.genome.fa.4.bt2 added #> 35c8643415668_GRCh38.primary_assembly.genome.fa.rev.1.bt2 added #> 35c862690a05a_GRCh38.primary_assembly.genome.fa.rev.2.bt2 added #> 35c8664d3620b_outfile.txt added #> 35c8656583273_GRCh37_to_GRCh38.chain added #> 35c861497364b_GRCh37_to_NCBI34.chain added #> 35c866fbab21b_GRCh37_to_NCBI35.chain added #> 35c866bb38cc0_GRCh37_to_NCBI36.chain added #> 35c866272c88a_GRCh38_to_GRCh37.chain added #> 35c864a066867_GRCh38_to_NCBI34.chain added #> 35c86201c403a_GRCh38_to_NCBI35.chain added #> 35c862d2ca0a0_GRCh38_to_NCBI36.chain added #> 35c866c1ecab0_NCBI34_to_GRCh37.chain added #> 35c861639db7d_NCBI34_to_GRCh38.chain added #> 35c864a9afee9_NCBI35_to_GRCh37.chain added #> 35c86ab4fbf0_NCBI35_to_GRCh38.chain added #> 35c8676b9d409_NCBI36_to_GRCh37.chain added #> 35c866e15c74b_NCBI36_to_GRCh38.chain added #> 35c86273b4a7d_GRCm38_to_NCBIM36.chain added #> 35c865092c6e_GRCm38_to_NCBIM37.chain added #> 35c86e89b952_NCBIM36_to_GRCm38.chain added #> 35c867756569c_NCBIM37_to_GRCm38.chain added #> 35c8631187d53_1000G_omni2.5.b37.vcf.gz added #> 35c863e2ce24e_1000G_omni2.5.b37.vcf.gz.tbi added #> 35c86b3b310c_Mills_and_1000G_gold_standard.indels.b37.vcf.gz added #> 35c8661af5314_Mills_and_1000G_gold_standard.indels.b37.vcf.gz.tbi added #> 35c862f733cd2_1000G_omni2.5.hg38.vcf.gz added #> 35c864ff39ec3_1000G_omni2.5.hg38.vcf.gz.tbi added #> 35c866bfe8948_Mills_and_1000G_gold_standard.indels.hg38.vcf.gz added #> 35c8643bee499_Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi added #> 35c865104158c_af-only-gnomad.raw.sites.vcf added #> 35c865f9f1750_af-only-gnomad.raw.sites.vcf.idx added #> 35c867003b02_Mutect2-exome-panel.vcf.idx added #> 35c867794b5e6_Mutect2-WGS-panel-b37.vcf added #> 35c864472795b_Mutect2-WGS-panel-b37.vcf.idx added #> 35c865d586d75_small_exac_common_3.vcf added #> 35c86c2bec31_small_exac_common_3.vcf.idx added #> 35c86342d2b77_1000g_pon.hg38.vcf.gz added #> 35c86490bfa35_1000g_pon.hg38.vcf.gz.tbi added #> 35c866e9eb4bb_af-only-gnomad.hg38.vcf.gz added #> 35c867e3393de_af-only-gnomad.hg38.vcf.gz.tbi added #> 35c8669283a6f_small_exac_common_3.hg38.vcf.gz added #> 35c861bcb555b_small_exac_common_3.hg38.vcf.gz.tbi added #> 35c866a525e8f_gencode.v41.annotation.gtf added #> 35c867f6215ec_gencode.v42.annotation.gtf added #> 35c8666665444_gencode.vM30.annotation.gtf added #> 35c8675075a7f_gencode.vM31.annotation.gtf added #> 35c86761be9f6_gencode.v41.transcripts.fa added #> 35c86547c1b90_gencode.v41.transcripts.fa.fai added #> 35c861c42a4fc_gencode.v42.transcripts.fa added #> 35c867b251664_gencode.v42.transcripts.fa.fai added #> 35c866305d4e2_gencode.vM30.pc_transcripts.fa added #> 35c861398fb98_gencode.vM30.pc_transcripts.fa.fai added #> 35c862c3d93b8_gencode.vM31.pc_transcripts.fa added #> 35c862132b730_gencode.vM31.pc_transcripts.fa.fai added #> 35c861ed42ca4_GRCh38.primary_assembly.genome.fa.1.ht2 added #> 35c86dece6cc_GRCh38.primary_assembly.genome.fa.2.ht2 added #> 35c8650a5f402_GRCh38.primary_assembly.genome.fa.3.ht2 added #> 35c866ec7cb67_GRCh38.primary_assembly.genome.fa.4.ht2 added #> 35c8679eb7014_GRCh38.primary_assembly.genome.fa.5.ht2 added #> 35c861464d89b_GRCh38.primary_assembly.genome.fa.6.ht2 added #> 35c863fcbe0f3_GRCh38.primary_assembly.genome.fa.7.ht2 added #> 35c86598a8764_GRCh38.primary_assembly.genome.fa.8.ht2 added #> 35c861b65139d_GRCh38_full_analysis_set_plus_decoy_hla.fa.fai added #> 35c86376096d9_GRCh38_full_analysis_set_plus_decoy_hla.fa.amb added #> 35c861dfd00c0_GRCh38_full_analysis_set_plus_decoy_hla.fa.ann added #> 35c8678bd8113_GRCh38_full_analysis_set_plus_decoy_hla.fa.bwt added #> 35c86438c830a_GRCh38_full_analysis_set_plus_decoy_hla.fa.pac added #> 35c86522a2c37_GRCh38_full_analysis_set_plus_decoy_hla.fa.sa added #> 35c8641c97b48_GRCh38_full_analysis_set_plus_decoy_hla.fa added #> 35c86322b37c5_GRCh38.primary_assembly.genome.fa.fai added #> 35c86505dc015_GRCh38.primary_assembly.genome.fa.amb added #> 35c862af1b5b8_GRCh38.primary_assembly.genome.fa.ann added #> 35c864df68d20_GRCh38.primary_assembly.genome.fa.bwt added #> 35c863ab01ea4_GRCh38.primary_assembly.genome.fa.pac added #> 35c862a53cba4_GRCh38.primary_assembly.genome.fa.sa added #> 35c86345ce164_GRCh38.primary_assembly.genome.fa added #> 35c862fb77923_hs37d5.fa.fai added #> 35c86206fb59a_hs37d5.fa.amb added #> 35c868d8fcf4_hs37d5.fa.ann added #> 35c864bfa1e1f_hs37d5.fa.bwt added #> 35c861b94cbff_hs37d5.fa.pac added #> 35c866bded1d6_hs37d5.fa.sa added #> 35c865f9319b7_hs37d5.fa added #> 35c8647d25fb7_complete_ref_lens.bin added #> 35c86d118906_ctable.bin added #> 35c867e67465b_ctg_offsets.bin added #> 35c8655bf4683_duplicate_clusters.tsv added #> 35c865db77d08_info.json added #> 35c866d2f11c2_mphf.bin added #> 35c864faab698_pos.bin added #> 35c86721c55a4_pre_indexing.log added #> 35c862cfaf2b5_rank.bin added #> 35c8629353dfc_ref_indexing.log added #> 35c86d816941_refAccumLengths.bin added #> 35c86645b898e_reflengths.bin added #> 35c8647323ebc_refseq.bin added #> 35c8663eea54_seq.bin added #> 35c8627e80c98_versionInfo.json added #> 35c86195c6af3_salmon_index added #> 35c864808659d_chrLength.txt added #> 35c865a13445d_chrName.txt added #> 35c8669ba2b09_chrNameLength.txt added #> 35c8672fa1b55_chrStart.txt added #> 35c862809d17d_exonGeTrInfo.tab added #> 35c86246a49ad_exonInfo.tab added #> 35c861d4de6f9_geneInfo.tab added #> 35c865c66b2e2_Genome added #> 35c865421c2d1_genomeParameters.txt added #> 35c863dbd9c94_Log.out added #> 35c86653fafd6_SA added #> 35c86201be0f0_SAindex added #> 35c8659526893_sjdbInfo.txt added #> 35c86511e81ad_sjdbList.fromGTF.out.tab added #> 35c867faefaa8_sjdbList.out.tab added #> 35c862124c84a_transcriptInfo.tab added #> 35c865e300ab3_GRCh38.GENCODE.v42_100 added #> 35c867e164103_knownGene_hg38.sql added #> 35c8676e40ecd_knownGene_hg38.txt added #> 35c863be787bc_refGene_hg38.sql added #> 35c866b4552c6_refGene_hg38.txt added #> 35c86468ec565_knownGene_mm39.sql added #> 35c862e03dd60_knownGene_mm39.txt added #> 35c861840457b_refGene_mm39.sql added #> 35c866fc40362_refGene_mm39.txt added #> dataHub with 144 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>             name                    #>   BFC899  | GRCh37_to_GRCh38.chain  #>   BFC1927 | GRCm38_to_NCBIM36.chain #>   BFC2825 | GRCh37_to_GRCh38.chain  #>   BFC2826 | outfile.txt             #>   BFC2955 | outfile.txt             #>   ...       ...                     #>   BFC4626 | refGene_hg38.txt        #>   BFC4627 | knownGene_mm39.sql      #>   BFC4628 | knownGene_mm39.txt      #>   BFC4629 | refGene_mm39.sql        #>   BFC4630 | refGene_mm39.txt        #>           Path                                                                #>   BFC899  /tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC1927 /tmp/Rtmp4dXPOh/gcpData/GRCm38_to_NCBIM36.chain                     #>   BFC2825 /tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC2826 /tmp/RtmpkdDQm8/working_dir/RtmpjAGUWK/test_SharedData/outfile.txt  #>   BFC2955 /tmp/RtmpRwEJgD/working_dir/Rtmpilpixw/test_SharedData/outfile.txt  #>   ...     ...                                                                 #>   BFC4626 https://storage.googleapis.com/reusedata/ucsc_database/refGene_h... #>   BFC4627 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4628 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4629 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC4630 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... dd <- dataSearch(c(\"liftover\", \"GRCh38\")) dataNames(dd) #>  [1] \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" #>  [4] \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" #>  [7] \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" #> [10] \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" \"GRCh37_to_GRCh38.chain\" #> [13] \"GRCh37_to_GRCh38.chain\" \"GRCh38_to_GRCh37.chain\" \"GRCh38_to_NCBI34.chain\" #> [16] \"GRCh38_to_NCBI35.chain\" \"GRCh38_to_NCBI36.chain\" \"NCBI34_to_GRCh38.chain\" #> [19] \"NCBI35_to_GRCh38.chain\" \"NCBI36_to_GRCh38.chain\" dataParams(dd) #>  [1] \"species: human; from: GRCh37; to: GRCh38\" #>  [2] \"species: human; from: GRCh37; to: GRCh38\" #>  [3] \"species: human; from: GRCh37; to: GRCh38\" #>  [4] \"species: human; from: GRCh37; to: GRCh38\" #>  [5] \"species: human; from: GRCh37; to: GRCh38\" #>  [6] \"species: human; from: GRCh37; to: GRCh38\" #>  [7] \"species: human; from: GRCh37; to: GRCh38\" #>  [8] \"species: human; from: GRCh37; to: GRCh38\" #>  [9] \"species: human; from: GRCh37; to: GRCh38\" #> [10] \"species: human; from: GRCh37; to: GRCh38\" #> [11] \"species: human; from: GRCh37; to: GRCh38\" #> [12] \"species: human; from: GRCh37; to: GRCh38\" #> [13] \"species: human; from: GRCh37; to: GRCh38\" #> [14] \"species: human; from: GRCh38; to: GRCh37\" #> [15] \"species: human; from: GRCh38; to: NCBI34\" #> [16] \"species: human; from: GRCh38; to: NCBI35\" #> [17] \"species: human; from: GRCh38; to: NCBI36\" #> [18] \"species: human; from: NCBI34; to: GRCh38\" #> [19] \"species: human; from: NCBI35; to: GRCh38\" #> [20] \"species: human; from: NCBI36; to: GRCh38\" dataNotes(dd) #>  [1] \"ensembl liftover human GRCh37 GRCh38\" #>  [2] \"ensembl liftover human GRCh37 GRCh38\" #>  [3] \"ensembl liftover human GRCh37 GRCh38\" #>  [4] \"ensembl liftover human GRCh37 GRCh38\" #>  [5] \"ensembl liftover human GRCh37 GRCh38\" #>  [6] \"ensembl liftover human GRCh37 GRCh38\" #>  [7] \"ensembl liftover human GRCh37 GRCh38\" #>  [8] \"ensembl liftover human GRCh37 GRCh38\" #>  [9] \"ensembl liftover human GRCh37 GRCh38\" #> [10] \"ensembl liftover human GRCh37 GRCh38\" #> [11] \"ensembl liftover human GRCh37 GRCh38\" #> [12] \"ensembl liftover human GRCh37 GRCh38\" #> [13] \"ensembl liftover human GRCh37 GRCh38\" #> [14] \"ensembl liftover human GRCh38 GRCh37\" #> [15] \"ensembl liftover human GRCh38 NCBI34\" #> [16] \"ensembl liftover human GRCh38 NCBI35\" #> [17] \"ensembl liftover human GRCh38 NCBI36\" #> [18] \"ensembl liftover human NCBI34 GRCh38\" #> [19] \"ensembl liftover human NCBI35 GRCh38\" #> [20] \"ensembl liftover human NCBI36 GRCh38\" dataTags(dd) #>  [1] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" dataYml(dd) #>  [1] \"/tmp/RtmpMZs31N/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [2] \"/tmp/Rtmp4dXPOh/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [3] \"/tmp/RtmpMF39J6/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [4] \"/tmp/Rtmp8mVqnL/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [5] \"/tmp/RtmpKEpli0/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [6] \"/tmp/Rtmpm1thzu/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [7] \"/tmp/Rtmp2f3PBx/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [8] \"/tmp/RtmpjrG1vn/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #>  [9] \"/tmp/RtmpldLvSD/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #> [10] \"/tmp/RtmpTvoXjc/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #> [11] \"/tmp/Rtmp852CtF/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #> [12] \"/tmp/Rtmpx6qi6B/gcpData/genome_liftover_human_GRCh37_GRCh38.yml\"                                   #> [13] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_GRCh37_GRCh38.yml\" #> [14] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_GRCh38_GRCh37.yml\" #> [15] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_GRCh38_NCBI34.yml\" #> [16] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_GRCh38_NCBI35.yml\" #> [17] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_GRCh38_NCBI36.yml\" #> [18] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_NCBI34_GRCh38.yml\" #> [19] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_NCBI35_GRCh38.yml\" #> [20] \"https://storage.googleapis.com/reusedata/ensembl_liftover/genome_liftover_human_NCBI36_GRCh38.yml\" toList(dd) #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpMF39J6/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmp8mVqnL/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpKEpli0/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmpm1thzu/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmp2f3PBx/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpjrG1vn/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpldLvSD/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/RtmpTvoXjc/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmp852CtF/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"/tmp/Rtmpx6qi6B/gcpData/GRCh37_to_GRCh38.chain\" #>  #> $GRCh37_to_GRCh38.chain #> [1] \"gs://reusedata/ensembl_liftover/GRCh37_to_GRCh38.chain\" #>  #> $GRCh38_to_GRCh37.chain #> [1] \"gs://reusedata/ensembl_liftover/GRCh38_to_GRCh37.chain\" #>  #> $GRCh38_to_NCBI34.chain #> [1] \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI34.chain\" #>  #> $GRCh38_to_NCBI35.chain #> [1] \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI35.chain\" #>  #> $GRCh38_to_NCBI36.chain #> [1] \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI36.chain\" #>  #> $NCBI34_to_GRCh38.chain #> [1] \"gs://reusedata/ensembl_liftover/NCBI34_to_GRCh38.chain\" #>  #> $NCBI35_to_GRCh38.chain #> [1] \"gs://reusedata/ensembl_liftover/NCBI35_to_GRCh38.chain\" #>  #> $NCBI36_to_GRCh38.chain #> [1] \"gs://reusedata/ensembl_liftover/NCBI36_to_GRCh38.chain\" #>  toList(dd, format = \"yaml\") #> [1] \"GRCh37_to_GRCh38.chain: /tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/RtmpMF39J6/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmp8mVqnL/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/RtmpKEpli0/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmpm1thzu/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmp2f3PBx/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/RtmpjrG1vn/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/RtmpldLvSD/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/RtmpTvoXjc/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmp852CtF/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: /tmp/Rtmpx6qi6B/gcpData/GRCh37_to_GRCh38.chain\\nGRCh37_to_GRCh38.chain: gs://reusedata/ensembl_liftover/GRCh37_to_GRCh38.chain\\nGRCh38_to_GRCh37.chain: gs://reusedata/ensembl_liftover/GRCh38_to_GRCh37.chain\\nGRCh38_to_NCBI34.chain: gs://reusedata/ensembl_liftover/GRCh38_to_NCBI34.chain\\nGRCh38_to_NCBI35.chain: gs://reusedata/ensembl_liftover/GRCh38_to_NCBI35.chain\\nGRCh38_to_NCBI36.chain: gs://reusedata/ensembl_liftover/GRCh38_to_NCBI36.chain\\nNCBI34_to_GRCh38.chain: gs://reusedata/ensembl_liftover/NCBI34_to_GRCh38.chain\\nNCBI35_to_GRCh38.chain: gs://reusedata/ensembl_liftover/NCBI35_to_GRCh38.chain\\nNCBI36_to_GRCh38.chain: gs://reusedata/ensembl_liftover/NCBI36_to_GRCh38.chain\" toList(dd, format = \"json\", file = tempfile()) #> File is saved as: \"/tmp/Rtmp7Lq2kA/file35c863b8546a1\" #> { #>   \"GRCh37_to_GRCh38.chain\": \"/tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.1\": \"/tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.2\": \"/tmp/RtmpMF39J6/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.3\": \"/tmp/Rtmp8mVqnL/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.4\": \"/tmp/RtmpKEpli0/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.5\": \"/tmp/Rtmpm1thzu/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.6\": \"/tmp/Rtmp2f3PBx/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.7\": \"/tmp/RtmpjrG1vn/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.8\": \"/tmp/RtmpldLvSD/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.9\": \"/tmp/RtmpTvoXjc/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.10\": \"/tmp/Rtmp852CtF/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.11\": \"/tmp/Rtmpx6qi6B/gcpData/GRCh37_to_GRCh38.chain\", #>   \"GRCh37_to_GRCh38.chain.12\": \"gs://reusedata/ensembl_liftover/GRCh37_to_GRCh38.chain\", #>   \"GRCh38_to_GRCh37.chain\": \"gs://reusedata/ensembl_liftover/GRCh38_to_GRCh37.chain\", #>   \"GRCh38_to_NCBI34.chain\": \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI34.chain\", #>   \"GRCh38_to_NCBI35.chain\": \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI35.chain\", #>   \"GRCh38_to_NCBI36.chain\": \"gs://reusedata/ensembl_liftover/GRCh38_to_NCBI36.chain\", #>   \"NCBI34_to_GRCh38.chain\": \"gs://reusedata/ensembl_liftover/NCBI34_to_GRCh38.chain\", #>   \"NCBI35_to_GRCh38.chain\": \"gs://reusedata/ensembl_liftover/NCBI35_to_GRCh38.chain\", #>   \"NCBI36_to_GRCh38.chain\": \"gs://reusedata/ensembl_liftover/NCBI36_to_GRCh38.chain\" #> }"},{"path":"/reference/dataSearch.html","id":null,"dir":"Reference","previous_headings":"","what":"dataSearch\nsearch data in local data caching system — dataSearch","title":"dataSearch\nsearch data in local data caching system — dataSearch","text":"dataSearch search data local data caching system","code":""},{"path":"/reference/dataSearch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataSearch\nsearch data in local data caching system — dataSearch","text":"","code":"dataSearch(keywords = character(), cachePath = \"ReUseData\")"},{"path":"/reference/dataSearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataSearch\nsearch data in local data caching system — dataSearch","text":"keywords character vector keywords matched local datasets. matches \"notes\" generating data using getData(notes = ). Keywords can tag data #tag format. specified, function returns full data list. cachePath character string data cache. Must match one specified dataUpdate(). Default \"ReUseData\".","code":""},{"path":"/reference/dataSearch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataSearch\nsearch data in local data caching system — dataSearch","text":"dataHub object containing information local data cache, e.g., data name, data path, etc.","code":""},{"path":"/reference/dataSearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataSearch\nsearch data in local data caching system — dataSearch","text":"","code":"dataSearch() #> dataHub with 144 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>             name                    #>   BFC899  | GRCh37_to_GRCh38.chain  #>   BFC1927 | GRCm38_to_NCBIM36.chain #>   BFC2825 | GRCh37_to_GRCh38.chain  #>   BFC2826 | outfile.txt             #>   BFC2955 | outfile.txt             #>   ...       ...                     #>   BFC4626 | refGene_hg38.txt        #>   BFC4627 | knownGene_mm39.sql      #>   BFC4628 | knownGene_mm39.txt      #>   BFC4629 | refGene_mm39.sql        #>   BFC4630 | refGene_mm39.txt        #>           Path                                                                #>   BFC899  /tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC1927 /tmp/Rtmp4dXPOh/gcpData/GRCm38_to_NCBIM36.chain                     #>   BFC2825 /tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC2826 /tmp/RtmpkdDQm8/working_dir/RtmpjAGUWK/test_SharedData/outfile.txt  #>   BFC2955 /tmp/RtmpRwEJgD/working_dir/Rtmpilpixw/test_SharedData/outfile.txt  #>   ...     ...                                                                 #>   BFC4626 https://storage.googleapis.com/reusedata/ucsc_database/refGene_h... #>   BFC4627 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4628 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4629 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC4630 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... dataSearch(c(\"gencode\"))  #> dataHub with 52 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>             name                        #>   BFC4549 | gencode.v41.annotation.gtf  #>   BFC4550 | gencode.v42.annotation.gtf  #>   BFC4551 | gencode.vM30.annotation.gtf #>   BFC4552 | gencode.vM31.annotation.gtf #>   BFC4553 | gencode.v41.transcripts.fa  #>   ...       ...                         #>   BFC4618 | sjdbInfo.txt                #>   BFC4619 | sjdbList.fromGTF.out.tab    #>   BFC4620 | sjdbList.out.tab            #>   BFC4621 | transcriptInfo.tab          #>   BFC4622 | GRCh38.GENCODE.v42_100      #>           Path                                                                #>   BFC4549 https://storage.googleapis.com/reusedata/gencode_annotation/genc... #>   BFC4550 https://storage.googleapis.com/reusedata/gencode_annotation/genc... #>   BFC4551 https://storage.googleapis.com/reusedata/gencode_annotation/genc... #>   BFC4552 https://storage.googleapis.com/reusedata/gencode_annotation/genc... #>   BFC4553 https://storage.googleapis.com/reusedata/gencode_transcriptome/g... #>   ...     ...                                                                 #>   BFC4618 https://storage.googleapis.com/reusedata/STAR_index/GRCh38.GENCO... #>   BFC4619 https://storage.googleapis.com/reusedata/STAR_index/GRCh38.GENCO... #>   BFC4620 https://storage.googleapis.com/reusedata/STAR_index/GRCh38.GENCO... #>   BFC4621 https://storage.googleapis.com/reusedata/STAR_index/GRCh38.GENCO... #>   BFC4622 https://storage.googleapis.com/reusedata/STAR_index/GRCh38.GENCO... dataSearch(\"#gatk\") #> dataHub with 0 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols()"},{"path":"/reference/dataUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"dataUpdate — dataUpdate","title":"dataUpdate — dataUpdate","text":"Function update local data records reading yaml files specified directory recursively.","code":""},{"path":"/reference/dataUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataUpdate — dataUpdate","text":"","code":"dataUpdate(   dir,   cachePath = \"ReUseData\",   outMeta = FALSE,   keepTags = TRUE,   cleanup = FALSE,   cloud = FALSE,   remote = FALSE,   checkData = TRUE,   duplicate = FALSE )"},{"path":"/reference/dataUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataUpdate — dataUpdate","text":"dir character string directory data saved. Data information collected recursively within directory. cachePath character string specifying name BiocFileCache object store curated data resources. specified, must match cachePath argument dataSearch. Default \"ReUseData\". outMeta Logical. TRUE, \"meta_data.csv\" file generated dir, containing information available datasets directory: file path yaml files, yaml entries including parameter values data recipe, file path datasets, notes, version (getData()), available data generating date. keepTags keep prior assigned data tags. Default TRUE. cleanup remove invalid intermediate files. Default FALSE. cases one data recipe (parameter values) evaluated multiple times, data file(s) match multiple intermediate files (e.g., .yml). cleanup remove older intermediate files, keep recent ones matches data file. intermediate files match data file, cleanup also remove . cloud Whether return pregenerated data Google Cloud bucket ReUseData. Default FALSE. remote Whether use csv file (containing information pregenerated data Google Cloud) GitHub, --date. works cloud = TRUE. Default FALSE. checkData check data (listed \"# output: \" yml file) exists. , include output csv file. argument added internal testing purpose. duplicate Whether remove duplicates. TRUE, older version duplicates removed.","code":""},{"path":"/reference/dataUpdate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataUpdate — dataUpdate","text":"dataHub object containing information local data cache, e.g., data name, data path, etc.","code":""},{"path":"/reference/dataUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataUpdate — dataUpdate","text":"Users can directly retrieve information available datasets using meta_data(dir=), generates data frame R information described can saved . dataUpdate extra check datasets (check file path \"output\" column), remove invalid ones, e.g., empty non-existing file path, create data cache valid datasets.","code":""},{"path":"/reference/dataUpdate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataUpdate — dataUpdate","text":"","code":"## Generate data if (FALSE) { library(Rcwl) outdir <- file.path(tempdir(), \"SharedData\")  echo_out <- recipeLoad(\"echo_out\") Rcwl::inputs(echo_out) echo_out$input <- \"Hello World!\" echo_out$outfile <- \"outfile\" res <- getData(echo_out,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\"),                showLog = TRUE)  ensembl_liftover <- recipeLoad(\"ensembl_liftover\") Rcwl::inputs(ensembl_liftover) ensembl_liftover$species <- \"human\" ensembl_liftover$from <- \"GRCh37\" ensembl_liftover$to <- \"GRCh38\" res <- getData(ensembl_liftover,         outdir = outdir,          notes = c(\"ensembl\", \"liftover\", \"human\", \"GRCh37\", \"GRCh38\"),         showLog = TRUE)  ## Update data cache (with or without prebuilt data sets from ReUseData cloud bucket) dataUpdate(dir = outdir) dataUpdate(dir = outdir, cloud = TRUE)  ## newly generated data are now cached and searchable dataSearch(c(\"hello\", \"world\")) dataSearch(c(\"ensembl\", \"liftover\"))  ## both locally generated data and google cloud data!  }"},{"path":"/reference/getCloudData.html","id":null,"dir":"Reference","previous_headings":"","what":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","title":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","text":"getCloudData Download pregenerated curated data sets ReUseData cloud bucket","code":""},{"path":"/reference/getCloudData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","text":"","code":"getCloudData(datahub, outdir = character())"},{"path":"/reference/getCloudData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","text":"datahub dataHub object returned dataSearch() 1 data record available ReUseData cloud bucket. outdir output directory data (concomitant annotation files) downloaded. recommended use new folder shared folder new --downloaded data.","code":""},{"path":"/reference/getCloudData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","text":"Data concomitant annotation files downloaded user-specified folder locally searchable dataSearch().","code":""},{"path":"/reference/getCloudData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"getCloudData Download the pregenerated curated data sets from\nReUseData cloud bucket — getCloudData","text":"","code":"outdir <- file.path(tempdir(), \"gcpData\") dh <- dataSearch(c(\"ensembl\", \"GRCh38\")) dh <- dh[grep(\"http\", dataPaths(dh))]  ## download data from google bucket getCloudData(dh[1], outdir = outdir) #> Data is downloaded:  #> /tmp/Rtmp7Lq2kA/gcpData/GRCh37_to_GRCh38.chain  ## Update local data caching dataUpdate(outdir)  ## no \"cloud=TRUE\" here, only showing local data cache #>  #> Updating data record... #> GRCh37_to_GRCh38.chain added #> dataHub with 145 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>             name                    #>   BFC899  | GRCh37_to_GRCh38.chain  #>   BFC1927 | GRCm38_to_NCBIM36.chain #>   BFC2825 | GRCh37_to_GRCh38.chain  #>   BFC2826 | outfile.txt             #>   BFC2955 | outfile.txt             #>   ...       ...                     #>   BFC4627 | knownGene_mm39.sql      #>   BFC4628 | knownGene_mm39.txt      #>   BFC4629 | refGene_mm39.sql        #>   BFC4630 | refGene_mm39.txt        #>   BFC4631 | GRCh37_to_GRCh38.chain  #>           Path                                                                #>   BFC899  /tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC1927 /tmp/Rtmp4dXPOh/gcpData/GRCm38_to_NCBIM36.chain                     #>   BFC2825 /tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC2826 /tmp/RtmpkdDQm8/working_dir/RtmpjAGUWK/test_SharedData/outfile.txt  #>   BFC2955 /tmp/RtmpRwEJgD/working_dir/Rtmpilpixw/test_SharedData/outfile.txt  #>   ...     ...                                                                 #>   BFC4627 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4628 https://storage.googleapis.com/reusedata/ucsc_database/knownGene... #>   BFC4629 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC4630 https://storage.googleapis.com/reusedata/ucsc_database/refGene_m... #>   BFC4631 /tmp/Rtmp7Lq2kA/gcpData/GRCh37_to_GRCh38.chain                       ## Now the data is available to use locally  dataSearch(c(\"ensembl\", \"GRCh38\")) #> dataHub with 21 records #> cache path:  /home/qhu/.cache/R/ReUseData  #> # dataUpdate() to update the local data cache #> # dataSearch() to query a specific dataset #> # Additional information can be retrieved using:  #> # dataNames(), dataParams(), dataNotes(), dataPaths(), dataTag() or mcols() #>  #>             name                   #>   BFC899  | GRCh37_to_GRCh38.chain #>   BFC2825 | GRCh37_to_GRCh38.chain #>   BFC3341 | GRCh37_to_GRCh38.chain #>   BFC3470 | GRCh37_to_GRCh38.chain #>   BFC3599 | GRCh37_to_GRCh38.chain #>   ...       ...                    #>   BFC4517 | GRCh38_to_NCBI36.chain #>   BFC4519 | NCBI34_to_GRCh38.chain #>   BFC4521 | NCBI35_to_GRCh38.chain #>   BFC4523 | NCBI36_to_GRCh38.chain #>   BFC4631 | GRCh37_to_GRCh38.chain #>           Path                                                                #>   BFC899  /tmp/RtmpMZs31N/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC2825 /tmp/Rtmp4dXPOh/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC3341 /tmp/RtmpMF39J6/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC3470 /tmp/Rtmp8mVqnL/gcpData/GRCh37_to_GRCh38.chain                      #>   BFC3599 /tmp/RtmpKEpli0/gcpData/GRCh37_to_GRCh38.chain                      #>   ...     ...                                                                 #>   BFC4517 https://storage.googleapis.com/reusedata/ensembl_liftover/GRCh38... #>   BFC4519 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI34... #>   BFC4521 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI35... #>   BFC4523 https://storage.googleapis.com/reusedata/ensembl_liftover/NCBI36... #>   BFC4631 /tmp/Rtmp7Lq2kA/gcpData/GRCh37_to_GRCh38.chain"},{"path":"/reference/getData.html","id":null,"dir":"Reference","previous_headings":"","what":"getData — getData","title":"getData — getData","text":"Evaluation data recipes generate curated dataset interest.","code":""},{"path":"/reference/getData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"getData — getData","text":"","code":"getData(   rcp,   outdir,   prefix = NULL,   notes = c(),   conda = FALSE,   BPPARAM = NULL,   ... )"},{"path":"/reference/getData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"getData — getData","text":"rcp data recipe cwlProcess S4 class. outdir Character string specifying directory store output files. automatically create exist provided. prefix Character string specifying file name annotation files (.yml, .cwl, .sh, .md5). notes User assigned notes/keywords annotate data used keywords matching dataSearch(keywords = ). conda Whether use conda install required software evaluating data recipe CWL workflow. Default FALSE. BPPARAM options BiocParallel::bpparam. ... Arguments passed Rcwl:runCWL().","code":""},{"path":"/reference/getData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"getData — getData","text":"data files 4 meta files: .cwl: cwl script internally run get data; .yml: input parameter values data recipe user specified data annotation notes, versions etc; .sh: script data processing; .md: checksum file verify integrity generated data files.","code":""},{"path":"/reference/getData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"getData — getData","text":"","code":"if (FALSE) { library(Rcwl) outdir <- file.path(tempdir(), \"SharedData\")  ## Example 1 echo_out <- recipeLoad(\"echo_out\") Rcwl::inputs(echo_out) echo_out$input <- \"Hello World!\" echo_out$outfile <- \"outfile\" res <- getData(echo_out,                outdir = outdir,                notes = c(\"echo\", \"hello\", \"world\", \"txt\"),                showLog = TRUE)  # Example 2 ensembl_liftover <- recipeLoad(\"ensembl_liftover\") Rcwl::inputs(ensembl_liftover) ensembl_liftover$species <- \"human\" ensembl_liftover$from <- \"GRCh37\" ensembl_liftover$to <- \"GRCh38\"  res <- getData(ensembl_liftover,         outdir = outdir,          notes = c(\"ensembl\", \"liftover\", \"human\", \"GRCh37\", \"GRCh38\"),         showLog = TRUE) dir(outdir) }"},{"path":"/reference/meta_data.html","id":null,"dir":"Reference","previous_headings":"","what":"meta_data — meta_data","title":"meta_data — meta_data","text":"Functions generate meta csv file local cached dataset.","code":""},{"path":"/reference/meta_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meta_data — meta_data","text":"","code":"meta_data(dir = \"\", cleanup = FALSE, checkData = TRUE)"},{"path":"/reference/meta_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"meta_data — meta_data","text":"dir path shared data folder. cleanup remove invalid intermediate files. Default FALSE. cases one data recipe (parameter values) evaluated multiple times, data file(s) match multiple intermediate files (e.g., .yml). cleanup remove older intermediate files, keep recent ones matches data file. intermediate files match data file, cleanup also remove . checkData check data (listed \"# output: \" yml file) exists. , include output csv file. argument added internal testing purpose.","code":""},{"path":"/reference/meta_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"meta_data — meta_data","text":"data.frame yml file name, parameter values, data file paths, date, user-specified notes generating data getData().","code":""},{"path":"/reference/meta_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"meta_data — meta_data","text":"","code":"outdir <- file.path(tempdir(), \"SharedData\") meta_data(outdir) #> [1] yml    params output notes  date   <NA>   #> <0 rows> (or 0-length row.names)"},{"path":"/reference/recipeHub-class.html","id":null,"dir":"Reference","previous_headings":"","what":"recipeHub — recipeHub","title":"recipeHub — recipeHub","text":"recipeHub class, constructor, methods.","code":""},{"path":"/reference/recipeHub-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"recipeHub — recipeHub","text":"","code":"recipeHub(BFC)  recipeHub(BFC)  # S4 method for recipeHub show(object)  # S4 method for recipeHub,ANY,ANY,ANY [(x, i)  recipeNames(object)"},{"path":"/reference/recipeHub-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"recipeHub — recipeHub","text":"BFC BiocFileCache object created recipe recipes. object recipeHub object x recipeHub object integer index recipeHub object","code":""},{"path":"/reference/recipeHub-class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"recipeHub — recipeHub","text":"recipeHub: recipeHub object. [: recipeHub object subsetted. recipeNames: recipe names recipeHub object.","code":""},{"path":"/reference/recipeHub-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"recipeHub — recipeHub","text":"","code":"rcps <- recipeSearch(c(\"gencode\")) ## rcp1 <- rcps[1] ## recipeNames(rcp1)"},{"path":"/reference/recipeLoad.html","id":null,"dir":"Reference","previous_headings":"","what":"recipeLoad — recipeLoad","title":"recipeLoad — recipeLoad","text":"load data recipe(s) R environment.","code":""},{"path":"/reference/recipeLoad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"recipeLoad — recipeLoad","text":"","code":"recipeLoad(   rcp = c(),   cachePath = \"ReUseDataRecipe\",   env = .GlobalEnv,   return = TRUE )"},{"path":"/reference/recipeLoad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"recipeLoad — recipeLoad","text":"rcp (vector ) character string recipe name file path (recipeNames() mcols()$fpath column recipeHub object returned recipeSearch). cachePath character string recipe cache. Must match one specified recipeUpdate(). Default \"ReUseDataRecipe\". env R environment export . Default .GlobalEnv. return Whether return recipe user-assigned R object. Default TRUE, user need assign variable name recipe. e.g., rcp1 <- recipeLoad(). FALSE, loads recipe uses original name, user need assign new name. e.g., recipeLoad(return=TRUE). multiple recipes loaded, return=FALSE must used.","code":""},{"path":"/reference/recipeLoad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"recipeLoad — recipeLoad","text":"data recipe cwlProcess S4 class, ready evaluated R.","code":""},{"path":"/reference/recipeLoad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"recipeLoad — recipeLoad","text":"","code":"######################## ## Load single recipe ########################  library(Rcwl) #> Loading required package: yaml #> Loading required package: S4Vectors #> Loading required package: stats4 #> Loading required package: BiocGenerics #>  #> Attaching package: ‘BiocGenerics’ #> The following objects are masked from ‘package:stats’: #>  #>     IQR, mad, sd, var, xtabs #> The following objects are masked from ‘package:base’: #>  #>     Filter, Find, Map, Position, Reduce, anyDuplicated, aperm, append, #>     as.data.frame, basename, cbind, colnames, dirname, do.call, #>     duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted, #>     lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin, #>     pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table, #>     tapply, union, unique, unsplit, which.max, which.min #>  #> Attaching package: ‘S4Vectors’ #> The following object is masked from ‘package:utils’: #>  #>     findMatches #> The following objects are masked from ‘package:base’: #>  #>     I, expand.grid, unname recipeUpdate() #> Updating recipes... #>  #> recipeHub with 15 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                #>   BFC466 | bowtie2_index       #>   BFC467 | echo_out            #>   BFC468 | ensembl_liftover    #>   BFC469 | gcp_broad_gatk_hg19 #>   BFC470 | gcp_broad_gatk_hg38 #>   ...      ...                 #>   BFC476 | hisat2_index        #>   BFC477 | reference_genome    #>   BFC478 | salmon_index        #>   BFC479 | STAR_index          #>   BFC480 | ucsc_database       recipeSearch(\"liftover\") #> recipeHub with 1 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name             #>   BFC468 | ensembl_liftover rcp <- recipeLoad(\"ensembl_liftover\") #> Note: you need to assign a name for the recipe: rcpName <- recipeLoad('xx') #> Data recipe loaded! #> Use inputs() to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/ensembl_liftover.html #> for user instructions (e.g., eligible input values, data source, etc.) Rcwl::inputs(rcp) #> inputs: #>   species (species)  (string):   #>   from (from)  (string):   #>   to (to)  (string):   rm(rcp)  gencode_annotation <- recipeLoad(\"gencode_annotation\") #> Note: you need to assign a name for the recipe: rcpName <- recipeLoad('xx') #> Data recipe loaded! #> Use inputs() to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/gencode_annotation.html #> for user instructions (e.g., eligible input values, data source, etc.) inputs(gencode_annotation) #> inputs: #>   species (species)  (string):   #>   version (version)  (string):   rm(gencode_annotation)  ######################### ## Load multiple recipes #########################  rcphub <- recipeSearch(\"gencode\") recipeNames(rcphub) #> [1] \"gencode_annotation\"    \"gencode_genome_grch38\" \"gencode_transcripts\"   recipeLoad(recipeNames(rcphub), return=FALSE) #> Data recipe loaded! #> Use inputs(gencode_annotation) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/gencode_annotation.html #> for user instructions (e.g., eligible input values, data source, etc.) #> Data recipe loaded! #> Use inputs(gencode_genome_grch38) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/gencode_genome_grch38.html #> for user instructions (e.g., eligible input values, data source, etc.) #> Data recipe loaded! #> Use inputs(gencode_transcripts) to check required input parameters before evaluation. #> Check here: https://rcwl.org/dataRecipes/gencode_transcripts.html #> for user instructions (e.g., eligible input values, data source, etc.) inputs(gencode_transcripts) #> inputs: #>   species (species)  (string):   #>   version (version)  (string):"},{"path":"/reference/recipeMake.html","id":null,"dir":"Reference","previous_headings":"","what":"recipeMake — recipeMake","title":"recipeMake — recipeMake","text":"Constructor function data recipe","code":""},{"path":"/reference/recipeMake.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"recipeMake — recipeMake","text":"","code":"recipeMake(   shscript = character(),   paramID = c(),   paramType = c(),   outputID = c(),   outputType = c(\"File[]\"),   outputGlob = character(0),   requireTools = character(0) )"},{"path":"/reference/recipeMake.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"recipeMake — recipeMake","text":"shscript character string. Can take either file path user provided shell script, directly script content, converted data recipe. paramID Character vector. user specified parameter ID recipe. paramType Character vector specifying type paramID. One parameter can multiple types list. Valid values \"int\" integer, \"boolean\" boolean, \"float\" numeric, \"File\" file path, \"File[]\" array files, etc. Can also take \"double\", \"long\", \"null\", \"Directory\". See details. outputID ID output. outputType output type output. outputGlob glob pattern output files. E.g., \"hg19.*\". requireTools command-line tools used data processing/curation user-provided shell script. value must exactly match tool name. E.g., \"bwa\", \"samtools\", etc. particular version tool can specified format \"tool=version\", e.g., \"samtools=1.3\".","code":""},{"path":"/reference/recipeMake.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"recipeMake — recipeMake","text":"data recipe cwlProcess S4 class details shell script data processing/curation, inputs, outputs, required tools corresponding docker files. readily taken getData() evaluate shell scripts included generate data locally. Find details ?Rcwl::cwlProcess.","code":""},{"path":"/reference/recipeMake.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"recipeMake — recipeMake","text":"parameter types, details can found : \"https://www.commonwl.org/v1.2/CommandLineTool.html#CWLType\". recipeMake convenient function wrapping shell script data recipe (cwlProcess S4 class). Please use Rcwl::cwlProcess options functionalities, especially recipe gets complicated, e.g., needs docker image command-line tool, one parameter takes multiple types, etc. Refer recipe example: https://github.com/rworkflow/ReUseDataRecipe/blob/master/reference_genome.R","code":""},{"path":"/reference/recipeMake.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"recipeMake — recipeMake","text":"","code":"if (FALSE) { library(Rcwl) ############## ### example 1 ##############  script <- \" input=$1 outfile=$2 echo \\\"Print the input: $input\\\" > $outfile.txt \" rcp <- recipeMake(shscript = script,                   paramID = c(\"input\", \"outfile\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"echoout\",                   outputGlob = \"*.txt\") inputs(rcp) outputs(rcp) rcp$input <- \"Hello World!\" rcp$outfile <- \"outfile\" res <- getData(rcp, outdir = tempdir(),                notes = c(\"echo\", \"hello\", \"world\", \"txt\"),                showLog = TRUE) readLines(res$out)  ############## ### example 2 ##############  shfile <- system.file(\"extdata\", \"gencode_transcripts.sh\", package = \"ReUseData\") readLines(shfile) rcp <- recipeMake(shscript = shfile,                   paramID = c(\"species\", \"version\"),                   paramType = c(\"string\", \"string\"),                   outputID = \"transcripts\",                    outputGlob = \"*.transcripts.fa*\",                   requireTools = c(\"wget\", \"gzip\", \"samtools\")                   ) Rcwl::inputs(rcp) rcp$species <- \"human\" rcp$version <- \"42\" res <- getData(rcp,         outdir = tempdir(),          notes = c(\"gencode\", \"transcripts\", \"human\", \"42\"),         showLog = TRUE) res$output dir(tempdir()) }"},{"path":"/reference/recipeSearch.html","id":null,"dir":"Reference","previous_headings":"","what":"recipeSearch — recipeSearch","title":"recipeSearch — recipeSearch","text":"Search existing data recipes.","code":""},{"path":"/reference/recipeSearch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"recipeSearch — recipeSearch","text":"","code":"recipeSearch(keywords = character(), cachePath = \"ReUseDataRecipe\")"},{"path":"/reference/recipeSearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"recipeSearch — recipeSearch","text":"keywords character vector keywords matched recipe names. specified, function returns full recipe list. cachePath character string recipe cache. Must match one specified recipeUpdate(). Default \"ReUseDataRecipe\".","code":""},{"path":"/reference/recipeSearch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"recipeSearch — recipeSearch","text":"recipeHub object.","code":""},{"path":"/reference/recipeSearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"recipeSearch — recipeSearch","text":"","code":"recipeSearch() #> recipeHub with 15 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                #>   BFC466 | bowtie2_index       #>   BFC467 | echo_out            #>   BFC468 | ensembl_liftover    #>   BFC469 | gcp_broad_gatk_hg19 #>   BFC470 | gcp_broad_gatk_hg38 #>   ...      ...                 #>   BFC476 | hisat2_index        #>   BFC477 | reference_genome    #>   BFC478 | salmon_index        #>   BFC479 | STAR_index          #>   BFC480 | ucsc_database       recipeSearch(\"gencode\") #> recipeHub with 3 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name                  #>   BFC473 | gencode_annotation    #>   BFC474 | gencode_genome_grch38 #>   BFC475 | gencode_transcripts   recipeSearch(c(\"STAR\", \"index\")) #> recipeHub with 1 records #> cache path:  /home/qhu/.cache/R/ReUseDataRecipe  #> # recipeSearch() to query specific recipes using multipe keywords #> # recipeUpdate() to update the local recipe cache #>  #>            name       #>   BFC479 | STAR_index"},{"path":"/reference/recipeUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"recipeUpdate — recipeUpdate","title":"recipeUpdate — recipeUpdate","text":"Function sync get updated newly added data recipes pubic \"rworkflow/ReUseDataRecipe\" GitHub repository user-specified private GitHub repository.","code":""},{"path":"/reference/recipeUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"recipeUpdate — recipeUpdate","text":"","code":"recipeUpdate(   cachePath = \"ReUseDataRecipe\",   force = FALSE,   remote = FALSE,   repos = \"rworkflow/ReUseDataRecipe\" )"},{"path":"/reference/recipeUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"recipeUpdate — recipeUpdate","text":"cachePath character string specifying name BiocFileCache object store ReUseData recipes. specified , must use cachePath argument recipeSearch, recipeLoad. Default \"ReUseDataRecipe\". force Whether remove existing regenerate recipes cache. Default FALSE. use old recipes previously cached locally updated remotely (GitHub repos). remote Whether download data recipes directly GitHub repository. Default FALSE. repos GitHub repository containing data recipes synced local cache. works remote=TRUE. Default \"rworkflow/ReUseDataRecipe\" GitHub repository public data recipes saved, might --date recipes contained inReUseData package. can also private GitHub repository users save data recipes.","code":""},{"path":"/reference/recipeUpdate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"recipeUpdate — recipeUpdate","text":"recipeHub object.","code":""},{"path":"/reference/recipeUpdate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"recipeUpdate — recipeUpdate","text":"","code":"## recipeUpdate() ## recipeUpdate(force=TRUE) ## recipeUpdate(force = TRUE, remote = TRUE)"}]
